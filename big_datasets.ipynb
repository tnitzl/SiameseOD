{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "from Siamese.python_classes.training_models import train_dataset, bagging_ensamble_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26_optdigits.npz', '42_WBC.npz', '21_Lymphography.npz', '8_celeba.npz', '33_skin.npz', '34_smtp.npz', '28_pendigits.npz', '39_vertebral.npz', '11_donors.npz', '43_WDBC.npz', '7_Cardiotocography.npz', '36_speech.npz', '5_campaign.npz', '44_Wilt.npz', '10_cover.npz', '46_WPBC.npz', '37_Stamps.npz', '2_annthyroid.npz', '27_PageBlocks.npz', '31_satimage-2.npz', '3_backdoor.npz', '38_thyroid.npz', '29_Pima.npz', '24_mnist.npz', '15_Hepatitis.npz', '22_magic.gamma.npz', '16_http.npz', '32_shuttle.npz', '12_fault.npz', '47_yeast.npz', '13_fraud.npz', '35_SpamBase.npz', '41_Waveform.npz', '17_InternetAds.npz', '6_cardio.npz', '23_mammography.npz', '40_vowels.npz', '9_census.npz', '45_wine.npz', '25_musk.npz', '1_ALOI.npz', '18_Ionosphere.npz', '20_letter.npz', '19_landsat.npz', '14_glass.npz', '30_satellite.npz', '4_breastw.npz']\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "curent_dirctory = os.getcwd()\n",
    "file_directory = \"/Archiv/Classical/\"\n",
    "npz_files = [f for f in os.listdir(curent_dirctory + file_directory) if f.endswith('.npz')]\n",
    "print(npz_files)\n",
    "print(len(npz_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8_celeba.npz', '33_skin.npz', '34_smtp.npz', '11_donors.npz', '5_campaign.npz', '10_cover.npz', '3_backdoor.npz', '22_magic.gamma.npz', '16_http.npz', '32_shuttle.npz', '13_fraud.npz', '9_census.npz', '1_ALOI.npz']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "def filter_big_files(file: str, current_directory: str, file_classic_dataset: str) -> str:\n",
    "    data: np.lib.npyio.NpzFile = np.load(current_directory + file_classic_dataset + file, allow_pickle = True)\n",
    "    X: np.ndarray = data['X']\n",
    "\n",
    "    samples, _ = X.shape\n",
    "    if samples >= 15000:\n",
    "        return file\n",
    "    \n",
    "medium_files = [result for f in npz_files if (result := filter_big_files(f, curent_dirctory, file_directory)) is not None]\n",
    "print(medium_files)\n",
    "print(len(medium_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Seed ist: 61\n"
     ]
    }
   ],
   "source": [
    "random_seed = random.randint(0, 100)\n",
    "print(f'Der Seed ist: {random_seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter für die Anzhal der Files: 0\n",
      "##############Start Training with Dataset 8_celeba.npz######################\n",
      "Die gesamte Länge der Daten ist 202599\n",
      "Die Länge das Anomalydatensatzen ist 4547 und der normalen daten ist: 198052\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 227 und 1000\n",
      "Die ungelabelden parts dazu sind 4320 und 197052\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1278529 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 201372\n",
      "Die länge des ungelabendeten Datenloader ist: 787\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1138.1417943822728\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 879.445772023244\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 807.5967447244608\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 766.0963452038465\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 718.0245789062989\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 662.9737052237784\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 613.360693701514\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 588.7920234932197\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 575.7657623627045\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 557.6563630891634\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 543.8988541642228\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 528.2209069909753\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 519.8081238220642\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 501.37782625765414\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 491.85108485560755\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 483.90768835241494\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 476.7630991709483\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 471.42593457715526\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 470.0053917442834\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 464.95306683942243\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1227\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7859209895133972\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7714496850967407\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.9748809099197387\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.7854813456535339\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.607952880859375\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.7027701139450073\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.9549963116645813\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1.1430527329444886\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.2541836023330688\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.208266830444336\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.0756489515304566\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.888672947883606\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7093025326728821\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5912720799446106\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.564646863937378\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6333928346633911\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6848724603652954\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.693356168270111\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6915781021118164\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6894172787666321\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6870464205741882\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.684459674358368\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6819245934486389\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6791217207908631\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6762590050697327\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6734690308570862\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6705674529075623\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6675604701042175\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6649945020675659\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.662194573879242\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6595782160758972\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6568138718605041\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6539581179618835\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6512938618659974\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6484012961387634\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6458968997001648\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.643502140045166\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6408920049667358\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6382119059562683\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6358521699905395\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 201372\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 201372\n",
      "ROC-AUC: 0.5\n",
      "ROC_PR: 0.021452833561766284\n",
      "counter für die Anzhal der Files: 1\n",
      "##############Start Training with Dataset 33_skin.npz######################\n",
      "Die gesamte Länge der Daten ist 245057\n",
      "Die Länge das Anomalydatensatzen ist 50859 und der normalen daten ist: 194198\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1000 und 1000\n",
      "Die ungelabelden parts dazu sind 49859 und 193198\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 3000000 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 243057\n",
      "Die länge des ungelabendeten Datenloader ist: 950\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1533.7273846439193\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 840.8610891353068\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 534.476498540427\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 366.9273506188639\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 291.3929066082267\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 209.57265176975704\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 237.80760230174985\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 288.7720259461288\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 294.10387749944147\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 262.2967861470778\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 252.47202472929274\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 233.92503470472838\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 228.31314292020363\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 203.9616246513564\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 191.30346586557977\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 189.98989697529683\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 190.3883725363338\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 191.95775712513966\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 196.07498031513347\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 208.3966247330083\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 2000\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3.7656494677066803\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 5.6011563539505005\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 4.784361869096756\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.177124798297882\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 5.675327092409134\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 37.03632229566574\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 49.97746419906616\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 40.60328435897827\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 10.460459768772125\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 6.6126397252082825\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 4.504236280918121\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 2.2151123136281967\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.5058968830853701\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1.0194992758333683\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 2.6938413977622986\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 3.2742077708244324\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 3.117199718952179\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 2.4843712151050568\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1.5390561521053314\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.7232237830758095\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6958947107195854\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.695880800485611\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6957799941301346\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6958042457699776\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6955980360507965\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6955922991037369\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6953743547201157\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6951241940259933\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6950210556387901\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6949626356363297\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6946792528033257\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6946204379200935\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6945379376411438\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6943030282855034\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6941990703344345\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6940528899431229\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6938469558954239\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6937597021460533\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6936921998858452\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6934805735945702\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 243057\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 243057\n",
      "ROC-AUC: 0.4999094193521672\n",
      "ROC_PR: 0.20513295235274032\n",
      "counter für die Anzhal der Files: 2\n",
      "##############Start Training with Dataset 34_smtp.npz######################\n",
      "Die gesamte Länge der Daten ist 95156\n",
      "Die Länge das Anomalydatensatzen ist 30 und der normalen daten ist: 95126\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1 und 1000\n",
      "Die ungelabelden parts dazu sind 29 und 94126\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1001001 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94155\n",
      "Die länge des ungelabendeten Datenloader ist: 368\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 9.258968910104752\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 5.921009708553118\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2.8226792952443476\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.2669417029587213\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.3498577401556344\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.507763524344741\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2.352954021106136\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 3.446972029558444\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 3.3639348051609574\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2.476170022616878\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.6196657000097647\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.8667871034783922\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.46746503189301375\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.45673798150767514\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.8595845992342342\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1.6878971864243841\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 2.28497830491272\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 2.4148924928496664\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 2.1216003258829987\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 2.351251449861724\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1001\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.8889330253005028\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.14961730875074863\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.02536557673010975\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.011804959765868261\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.012702003868980682\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.015747605067645054\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.016931445649220223\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.022868048055897816\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.021476873943726105\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.022833849579185994\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.023752413061345123\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.024150986166215915\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.02505699731409905\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.02808714099228382\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.025754318688996136\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.02583230845630169\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.0281907320022583\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.025506293401122093\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.02514818124473095\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.024428853765130043\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.023458028212189674\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.022246893495321274\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.020406732335686684\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.01869291253387928\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.01674078218638897\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.01467118039727211\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.012110147625207901\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.009356261231005192\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.005442535970360041\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.0014598004054278135\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.000341970706358552\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 2.3820828118914505e-06\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 3.2247577053112764e-08\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 1.164153884403163e-09\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.0\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.0\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 2.0857078730784906e-08\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 5.8498699218034744e-08\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 6.636647675861695e-08\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 1.198278525293972e-07\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94155\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94155\n",
      "ROC-AUC: 0.7611785229922914\n",
      "ROC_PR: 0.6374101533298066\n",
      "counter für die Anzhal der Files: 3\n",
      "##############Start Training with Dataset 11_donors.npz######################\n",
      "Die gesamte Länge der Daten ist 619326\n",
      "Die Länge das Anomalydatensatzen ist 36710 und der normalen daten ist: 582616\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1000 und 1000\n",
      "Die ungelabelden parts dazu sind 35710 und 581616\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 3000000 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 617326\n",
      "Die länge des ungelabendeten Datenloader ist: 2412\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1256.229810954137\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 394.29679417620343\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 205.8411353350764\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 119.7373475814417\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 78.07006980351737\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 58.003145342241815\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 49.4784864825553\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 38.46489122945586\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 33.10308554490096\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 35.2327887954764\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 36.1113848770445\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 45.06774225909613\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 63.786479832928926\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 59.619764062871866\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 61.77388175549651\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 74.4237658255478\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 79.73969268636071\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 72.77313800345958\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 66.79526299662899\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 65.7850754473618\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 2000\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.9509692341089249\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.8001790344715118\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7196740135550499\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.6980437934398651\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.506829097867012\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6469056494534016\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.943458691239357\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6087755300104618\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.336142685264349\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.6513348370790482\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.9364628195762634\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.041810192167759\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.8714787811040878\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6263975203037262\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.5847959294915199\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.714962512254715\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7769646346569061\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.7125235050916672\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.696245476603508\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6970756649971008\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6974103972315788\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6980600133538246\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6979798153042793\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6989510506391525\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6995368078351021\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.7000732570886612\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.700553722679615\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.701025977730751\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.7016658559441566\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.701640859246254\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.7020563632249832\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.702604129910469\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.7032845765352249\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.7037449777126312\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.7039948999881744\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.7045499980449677\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.7043897733092308\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7053070366382599\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.7051981464028358\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.7051866501569748\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 617326\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 617326\n",
      "ROC-AUC: 0.4989881640119942\n",
      "ROC_PR: 0.057846259512801985\n",
      "counter für die Anzhal der Files: 4\n",
      "##############Start Training with Dataset 5_campaign.npz######################\n",
      "Die gesamte Länge der Daten ist 41188\n",
      "Die Länge das Anomalydatensatzen ist 4640 und der normalen daten ist: 36548\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 232 und 1000\n",
      "Die ungelabelden parts dazu sind 4408 und 35548\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1285824 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 39956\n",
      "Die länge des ungelabendeten Datenloader ist: 157\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1404.5508309481463\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1230.219910044654\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1161.8076518546911\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1074.4081055392267\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 949.3335599236675\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 829.9435245636187\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 779.9603121417845\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 744.5129743147343\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 689.5733817979774\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 668.0489532148698\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 655.489336600466\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 645.688793822586\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 638.0564612317033\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 637.7068976239572\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 631.8886520564971\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 625.8140544705293\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 627.6788890549274\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 619.5115812841982\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 608.0170899834881\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 600.6630857734597\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1232\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7366161108016968\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6715973973274231\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.8219528675079346\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.817726480960846\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6710302352905273\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6227025032043457\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.8654296636581421\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1.315203857421875\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.3983668327331542\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.0362186431884766\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6625054717063904\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6080860733985901\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.81374272108078\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.9941288709640503\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1.1726505756378174\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1.339527463912964\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1.4158226251602173\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1.4350712060928346\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1.3615868806838989\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1.232403612136841\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1.077218806743622\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.9034588813781739\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.7466529369354248\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.627713656425476\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.5711119711399079\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.5858456492424011\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6437412381172181\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.7247142672538758\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.7931107997894287\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.836466908454895\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.8475497364997864\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.8258939146995544\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.7777123212814331\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.7436994194984436\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.7404066801071167\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.7371801257133483\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.7338124513626099\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7301250219345092\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.7266569256782531\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.7230282306671143\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 39956\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 39956\n",
      "ROC-AUC: 0.4999718690221672\n",
      "ROC_PR: 0.11032135348883772\n",
      "counter für die Anzhal der Files: 5\n",
      "##############Start Training with Dataset 10_cover.npz######################\n",
      "Die gesamte Länge der Daten ist 286048\n",
      "Die Länge das Anomalydatensatzen ist 2747 und der normalen daten ist: 283301\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 137 und 1000\n",
      "Die ungelabelden parts dazu sind 2610 und 282301\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1155769 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 284911\n",
      "Die länge des ungelabendeten Datenloader ist: 1113\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 85268.96901801396\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1430.113164796544\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1188.9004561076792\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1186.598690136881\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1185.535775469572\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1185.4305339825905\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1185.3301100755186\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1185.3480171347246\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1185.363157226292\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1185.3413768138864\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1185.3745811420158\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1185.3613987513952\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1185.344697457585\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1185.364619602951\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1185.3579791266525\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1185.3546583342527\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1185.361298844347\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1185.3845419916468\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1185.3646197110975\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1185.341376442133\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1137\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7003673553466797\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6870546221733094\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.6723809480667114\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.6582891941070557\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6438698410987854\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6294864535331726\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.6153306245803833\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.5994395613670349\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.5872397780418396\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.5736754655838012\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.5583154320716858\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.5465722560882569\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.5349446415901185\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5255289912223816\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.5067929446697235\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.4993910312652588\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.48622480034828186\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.47663416862487795\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.46179277300834654\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.4536529302597046\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.44006316661834716\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.423269647359848\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.4168280899524689\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.4140422284603119\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.40087836384773257\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.3948341190814972\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.3907998263835907\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.3805999219417572\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.3787663817405701\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.3731657385826111\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.3731583297252655\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.36561037302017213\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.36948280334472655\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.3568184494972229\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.3605540573596954\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.386735200881958\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.35754576325416565\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.37093210220336914\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.37600854635238645\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.36942796111106874\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 284911\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 284911\n",
      "ROC-AUC: 0.5\n",
      "ROC_PR: 0.009160755463987\n",
      "counter für die Anzhal der Files: 6\n",
      "##############Start Training with Dataset 3_backdoor.npz######################\n",
      "Die gesamte Länge der Daten ist 95329\n",
      "Die Länge das Anomalydatensatzen ist 2329 und der normalen daten ist: 93000\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 116 und 1000\n",
      "Die ungelabelden parts dazu sind 2213 und 92000\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1129456 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94213\n",
      "Die länge des ungelabendeten Datenloader ist: 369\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 515.8963808922582\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 220.22324636516416\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 185.0629566487462\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 175.52357234483617\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 166.71071696465165\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 163.88363976794162\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 161.89827099434376\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 165.89671858569653\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 164.0862561482683\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 160.3640295034739\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 158.36543365337582\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 157.6825314121471\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 155.9937462547316\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 155.32348444844416\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 155.9305838429701\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 156.6751679118287\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 157.5905674560872\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 157.5270601685006\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 157.23857576244004\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 157.29226604852477\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1116\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7857954263687134\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6397430896759033\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.5195384860038758\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.4495765924453735\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.39349188208580016\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.3348591268062592\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.2874926269054413\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.24960085451602937\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.22501928806304933\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.19359438717365265\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.17691130340099334\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.15995434820652008\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.1445603549480438\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.129920993745327\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.09988595396280289\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.09493378698825836\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.08487227484583855\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.07605570405721665\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.08193819299340248\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.08168126046657562\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.06914199078455567\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.07701247557997704\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.07325985748320818\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.0858339548110962\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.07836079644039273\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.08092836283612996\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.10460283569991588\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.08633826549630612\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.10146450474858285\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.11361284777522088\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.10444305315613747\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.1281181439757347\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.10868828594684601\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.12407601624727249\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.09770945096970536\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.09994738176465034\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.14634884253609926\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.11073612794280052\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.09640293901320547\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.10860005915164947\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94213\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94213\n",
      "ROC-AUC: 0.9323560826342363\n",
      "ROC_PR: 0.874763940958402\n",
      "counter für die Anzhal der Files: 7\n",
      "##############Start Training with Dataset 22_magic.gamma.npz######################\n",
      "Die gesamte Länge der Daten ist 19020\n",
      "Die Länge das Anomalydatensatzen ist 6688 und der normalen daten ist: 12332\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 334 und 616\n",
      "Die ungelabelden parts dazu sind 6354 und 11716\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 696756 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 18070\n",
      "Die länge des ungelabendeten Datenloader ist: 71\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2432.7884265414764\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2081.2140318164925\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1940.0513721384782\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1902.2762008095208\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1834.5025963037\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1757.2585980641675\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1680.292492218354\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1619.7108252509213\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1577.3568327355088\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1547.417586529106\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1516.808075691128\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1484.2478679401922\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1453.2457674518391\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1412.886789875465\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1385.0060347669883\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1366.023762497632\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1346.641855479513\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1322.085384708043\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1305.7757082679182\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1295.877118067913\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 950\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.8013392090797424\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6739740073680878\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.6869664341211319\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.7416485548019409\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.7832881063222885\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.775423675775528\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7308408468961716\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6657556146383286\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.6563725471496582\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.7571062743663788\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8208335041999817\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7734629660844803\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6851634234189987\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6413903832435608\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6257422566413879\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.613967165350914\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6022274345159531\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.5937632471323013\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.5852209776639938\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.5794149935245514\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.5744464099407196\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.5711934715509415\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.5662516206502914\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.5617736577987671\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.5497099757194519\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.5373439341783524\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.5282090306282043\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.5237605273723602\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.5075344145298004\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.48644107580184937\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.47727345675230026\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.5259110629558563\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.5798739939928055\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.5149265825748444\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.44897010922431946\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.5008436813950539\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6218980550765991\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7281692028045654\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.8105811476707458\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.8605821281671524\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 18070\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 18070\n",
      "ROC-AUC: 0.8837245268436191\n",
      "ROC_PR: 0.846671214390979\n",
      "counter für die Anzhal der Files: 8\n",
      "##############Start Training with Dataset 16_http.npz######################\n",
      "Die gesamte Länge der Daten ist 567498\n",
      "Die Länge das Anomalydatensatzen ist 2211 und der normalen daten ist: 565287\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 110 und 1000\n",
      "Die ungelabelden parts dazu sind 2101 und 564287\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1122100 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 566388\n",
      "Die länge des ungelabendeten Datenloader ist: 2213\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 244.62775847598584\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 193.77633607648585\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 66.91881298018198\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 64.48137607452644\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 32.15121924202808\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 11.989434001219534\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 9.629013227258067\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 7.899932133971992\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 5.497868890989653\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 6.300334867389098\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 14.166415387642209\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 20.54111878312852\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 28.495938295484894\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 31.12859440872269\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 31.39591588863056\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 28.892686072709786\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 27.61026890804298\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 25.211760458176155\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 20.88961722990022\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 21.118632751387835\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1110\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 90.01635131835937\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 90.6340835571289\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 89.5530517578125\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 89.86191864013672\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 89.39861907958985\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 90.47965087890626\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 89.39861907958985\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 89.5530517578125\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 90.17078552246093\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 89.5530517578125\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 90.01635131835937\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 89.08975219726562\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 89.86191864013672\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 89.86191864013672\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 90.47965087890626\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 89.86191864013672\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 90.01635131835937\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 90.78851776123047\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 90.01635131835937\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 89.86191864013672\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 90.17078552246093\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 90.17078552246093\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 90.01635131835937\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 90.6340835571289\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 89.70748596191406\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 90.3252182006836\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 90.01635131835937\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 89.70748596191406\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 566388\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 566388\n",
      "ROC-AUC: 0.49964266970601806\n",
      "ROC_PR: 0.0037068318825847707\n",
      "counter für die Anzhal der Files: 9\n",
      "##############Start Training with Dataset 32_shuttle.npz######################\n",
      "Die gesamte Länge der Daten ist 49097\n",
      "Die Länge das Anomalydatensatzen ist 3511 und der normalen daten ist: 45586\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 175 und 1000\n",
      "Die ungelabelden parts dazu sind 3336 und 44586\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1205625 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 47922\n",
      "Die länge des ungelabendeten Datenloader ist: 188\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 293.467167310249\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 136.27422963761725\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 395.0768648981953\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 714.5783025459539\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 524.8058251411957\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 176.2918121380251\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 113.79056644464217\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 102.19491939022346\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 109.13433983997064\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 120.55630425965995\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 108.79160765173455\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 90.20388562747272\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 82.09454263405867\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 79.08997745357944\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 75.19625099563335\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 77.70112077059053\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 84.80309831184947\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 73.55105500063303\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 72.60742887462274\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 74.56003353521386\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1175\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7440079808235168\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7326447486877441\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7220967888832093\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.7058572769165039\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6966207027435303\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6785502314567566\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.664370596408844\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6517911434173584\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.6388288259506225\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.621695339679718\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6101405024528503\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.5965401411056519\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.5858813643455505\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5719305396080017\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.5598502397537232\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.5412164807319642\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.5301690936088562\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.5151664018630981\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.5030927658081055\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.4840677797794342\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.4733063876628876\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.4539357900619507\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.43954641819000245\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.42357062101364135\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.40854562520980836\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.3929664373397827\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.3762264549732208\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.3607338845729828\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.3457260012626648\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.33155509233474734\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.31488087177276614\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.3002119600772858\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.284170401096344\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.27097471356391906\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.2580863177776337\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.24494546055793762\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.23185219168663024\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.21841129362583162\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.20728634893894196\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.19562232196331025\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 47922\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 47922\n",
      "ROC-AUC: 0.968049147682258\n",
      "ROC_PR: 0.9433025870768638\n",
      "counter für die Anzhal der Files: 10\n",
      "##############Start Training with Dataset 13_fraud.npz######################\n",
      "Die gesamte Länge der Daten ist 284807\n",
      "Die Länge das Anomalydatensatzen ist 492 und der normalen daten ist: 284315\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 24 und 1000\n",
      "Die ungelabelden parts dazu sind 468 und 283315\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1024576 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 283783\n",
      "Die länge des ungelabendeten Datenloader ist: 1109\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 167.87175476161124\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 97.06125936107935\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 94.42398362179979\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 104.76359102245334\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 89.9792056326684\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 80.2521312401767\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 80.48194058939661\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 79.96221564741037\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 77.64216638972334\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 74.45276603929823\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 71.87785774345788\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 69.61354342002497\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 67.71587112216153\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 65.97029626994856\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 64.07574154530768\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 61.92123090244072\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 60.19976882350287\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 58.651472224672226\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 57.381094536661\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 56.515268850022785\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1024\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.22120635956525803\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.19170933961868286\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.18993127718567848\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.18887441605329514\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.1907004565000534\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.1845315769314766\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.17336302064359188\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.14387897215783596\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.14254089444875717\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.21263975277543068\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.24120230227708817\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.14523530937731266\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.10628779418766499\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.1637966949492693\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.24704662710428238\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.3313567414879799\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.4047084301710129\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.45807860791683197\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.5007215067744255\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.5263600721955299\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.5338505953550339\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.524128258228302\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.505026750266552\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.4697437211871147\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.42488256841897964\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.3802482858300209\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.32705139368772507\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.2679901421070099\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.20897986367344856\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.14844605699181557\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.10426899197045714\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.07280360348522663\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.06073895003646612\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.0634643230587244\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.0892031779512763\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.17521443963050842\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.32863885164260864\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.45739442110061646\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.4335131347179413\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.2846696078777313\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 283783\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 283783\n",
      "ROC-AUC: 0.8640326349925207\n",
      "ROC_PR: 0.6058584604400149\n",
      "counter für die Anzhal der Files: 11\n",
      "##############Start Training with Dataset 9_census.npz######################\n",
      "Die gesamte Länge der Daten ist 299285\n",
      "Die Länge das Anomalydatensatzen ist 18568 und der normalen daten ist: 280717\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 928 und 1000\n",
      "Die ungelabelden parts dazu sind 17640 und 279717\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 2789184 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 297357\n",
      "Die länge des ungelabendeten Datenloader ist: 1162\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1601.0105653782423\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1286.1387986730724\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1117.0476447734188\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 937.767071744944\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 863.0734017605998\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 801.9989090469966\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 713.4575451250118\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 669.0945999996952\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 623.545754501298\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 599.6203673722636\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 571.5226239359852\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 554.069089766291\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 529.717681951985\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 509.9367267311757\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 497.1097244229086\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 489.48377039849146\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 481.6783349741573\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 474.1578015286842\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 466.99889168760325\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 494.6213206068535\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1928\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2.920771062374115\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 5.295841366052628\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 3.1131614595651627\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 10.337341070175171\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 11.984145283699036\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 9.76147973537445\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 6.169993221759796\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.4768837988376617\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.7540308684110641\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.6983525156974792\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6281709372997284\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.9025017321109772\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7446110099554062\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.7120183482766151\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7181600108742714\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.7176605388522148\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7057823315262794\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6777879148721695\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6980014368891716\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.7362414076924324\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.7445140182971954\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.7306634113192558\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.7223189547657967\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.744663804769516\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.7978785112500191\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.8637195006012917\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.9077029377222061\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.8996505960822105\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.8627633824944496\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.7539727985858917\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.7162126898765564\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.715306781232357\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.7145353555679321\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.7142639458179474\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.712916299700737\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.712865561246872\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.7116623669862747\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7100348547101021\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.7090004906058311\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.708418607711792\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 297357\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 297357\n",
      "ROC-AUC: 0.49943335585609744\n",
      "ROC_PR: 0.05932263239136795\n",
      "counter für die Anzhal der Files: 12\n",
      "##############Start Training with Dataset 1_ALOI.npz######################\n",
      "Die gesamte Länge der Daten ist 49534\n",
      "Die Länge das Anomalydatensatzen ist 1508 und der normalen daten ist: 48026\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 75 und 1000\n",
      "Die ungelabelden parts dazu sind 1433 und 47026\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1080625 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 48459\n",
      "Die länge des ungelabendeten Datenloader ist: 190\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 677.9008776544113\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 664.0424709094186\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 657.6975141170182\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 655.4838231790128\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 655.7731255549834\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 655.0465421256495\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 651.4776803454422\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 650.9318636447431\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 649.6698177776761\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 648.9436332417122\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 647.3627734055513\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 646.6348004216891\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 646.487994477287\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 646.088279879528\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 646.1672479872566\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 645.8426700358931\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 645.7200488764096\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 645.5198163746771\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 645.1991909863767\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 644.5110130111283\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1075\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 6.51332368850708\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 3.90411319732666\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2.596790838241577\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.8372694730758667\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.2637743473052978\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.971437644958496\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7484215378761292\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6071332812309265\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.5888305306434631\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.5914238572120667\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.5891084671020508\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.5824150085449219\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.5799704670906067\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5784580707550049\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.576019012928009\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.5726186394691467\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.5751037001609802\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.5666990160942078\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.5652385473251342\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.566978657245636\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.5592459321022034\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.560036551952362\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.5553663372993469\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.559746241569519\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.5504307150840759\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.550351333618164\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.5455318331718445\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.5443034052848816\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.5393711924552917\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.5382007360458374\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.5370487213134766\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.531994640827179\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.5349210858345032\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.529857087135315\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.5330396175384522\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.5236756920814514\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.522732424736023\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.5189342260360718\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.5165200233459473\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.5187141418457031\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 48459\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 48459\n",
      "ROC-AUC: 0.5\n",
      "ROC_PR: 0.02957139024742566\n"
     ]
    }
   ],
   "source": [
    "roc_all = []\n",
    "pr_all = []\n",
    "\n",
    "counter = 0\n",
    "for file in medium_files:\n",
    "    print(f'counter für die Anzhal der Files: {counter}')\n",
    "    roc, pr = train_dataset(file, \n",
    "                            random_seed=random_seed,\n",
    "                            percentage_labeld=0.05,\n",
    "                            contrastiv_margin=10.0,\n",
    "                            lr_siamese=0.0001,\n",
    "                            lr_classifier=0.001,\n",
    "                            epochs_siamese=20,\n",
    "                            epochs_classifier=40,\n",
    "                            print_embeddeds=False,\n",
    "                            print_learning=False,\n",
    "                            )\n",
    "    \n",
    "    roc_all.append(roc)\n",
    "    pr_all.append(pr)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(roc_all)), roc_all, marker='o', color='b')\n",
    "plt.plot(range(len(pr_all)), pr_all, marker='x', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter für die Anzhal der Files: 0\n",
      "##############Start Training with Dataset 8_celeba.npz######################\n",
      "Die gesamte Länge der Daten ist 202599\n",
      "Die Länge das Anomalydatensatzen ist 4547 und der normalen daten ist: 198052\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 227 und 1000\n",
      "Die ungelabelden parts dazu sind 4320 und 197052\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1278529 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 201372\n",
      "Die länge des ungelabendeten Datenloader ist: 787\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1671.8359468843844\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1458.8312048132116\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1283.7850770692567\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1202.1724749529803\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1102.3621604148093\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1098.5412751496615\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1092.366843650291\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1075.8519124471152\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1035.9235147012246\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 997.2818555616163\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 973.770581225757\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 955.5180398415994\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 937.8194642518495\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 927.1144532105347\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 919.3976530852141\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 911.8291569890202\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 903.7989617913812\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 894.3214717158564\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 885.7836204735008\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 879.4756309898765\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1227\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7084469676017762\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7056462287902832\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.702939510345459\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.6996867060661316\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6967591762542724\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.692508852481842\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.6894032120704651\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6858856439590454\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.6818164467811585\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.6780616879463196\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6738134980201721\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6703630089759827\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6660388946533203\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6622755050659179\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6589368581771851\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6555421352386475\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6512043833732605\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6470149517059326\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6433252573013306\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.639692747592926\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6350064277648926\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6311233639717102\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6262085318565369\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6228055000305176\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6187855124473571\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6152727603912354\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6119869112968445\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6084789752960205\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.604512071609497\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.601387882232666\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.5977634787559509\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.5947193503379822\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.5912665128707886\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.5881511926651001\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.5848795652389527\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.5811542749404908\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.5769953727722168\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.5738774180412293\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.5703050255775451\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.5677663803100585\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 201372\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 201372\n",
      "ROC-AUC: 0.9407858130933291\n",
      "ROC_PR: 0.2959969717534362\n",
      "counter für die Anzhal der Files: 1\n",
      "##############Start Training with Dataset 33_skin.npz######################\n",
      "Die gesamte Länge der Daten ist 245057\n",
      "Die Länge das Anomalydatensatzen ist 50859 und der normalen daten ist: 194198\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1000 und 1000\n",
      "Die ungelabelden parts dazu sind 49859 und 193198\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 3000000 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 243057\n",
      "Die länge des ungelabendeten Datenloader ist: 950\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3038.598897056863\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2580.3892920701023\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2178.9008788020856\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1967.7509794791044\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1605.9460316617412\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1240.2780887028578\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1221.0916122487304\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1406.833322055796\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1456.56679750207\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1299.8931333371138\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1096.073688469646\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1064.5047479976677\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1088.7305277643661\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1079.1823626304306\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1026.768574093336\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 965.0997291224454\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 975.0741795529195\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1004.4645268999886\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 988.4192199628908\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 963.9718990135502\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 2000\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 4.812731444835663\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 4.481045633554459\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 4.187221974134445\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 3.812667340040207\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 3.3993867337703705\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 2.9865611493587494\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2.5474701523780823\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.110662654042244\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.6905928552150726\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.3056667000055313\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.962583139538765\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6896720752120018\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.5114591009914875\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.40464921295642853\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.34829865023493767\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.31989793106913567\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.3044874481856823\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.2986651286482811\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.29394857212901115\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.29185881838202477\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.2911672666668892\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.29065674915909767\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.29338663071393967\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.2956014685332775\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.298825915902853\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.30176470056176186\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.30497268587350845\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.3089672364294529\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.3151019848883152\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.31978124752640724\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.3241236098110676\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.3306664265692234\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.33540211245417595\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.34183087572455406\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.3467714823782444\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.3507828004658222\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.35451145097613335\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.3582450784742832\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.36363884061574936\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.3693191260099411\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 243057\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 243057\n",
      "ROC-AUC: 0.9814708848843696\n",
      "ROC_PR: 0.851384817765923\n",
      "counter für die Anzhal der Files: 2\n",
      "##############Start Training with Dataset 34_smtp.npz######################\n",
      "Die gesamte Länge der Daten ist 95156\n",
      "Die Länge das Anomalydatensatzen ist 30 und der normalen daten ist: 95126\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1 und 1000\n",
      "Die ungelabelden parts dazu sind 29 und 94126\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1001001 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94155\n",
      "Die länge des ungelabendeten Datenloader ist: 368\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 10.67149791721949\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 9.863097901647276\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 9.907438256892362\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 9.803634298141885\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 9.411709037423895\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 9.318051901369014\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 9.128165756694438\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 8.768279308127918\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 8.495123182876096\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 8.186159473258313\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 7.884704480430136\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 7.56567749653866\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 7.252103264276648\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 6.934633672669839\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 6.656527095181166\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 6.338145063834266\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 6.004612649755462\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 5.684036193982746\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 5.339984002941993\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 4.972405622689217\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1001\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.2202589102089405\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.2138756401836872\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.20736411213874817\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.20073559507727623\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.19404361769557\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.18723518773913383\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.18044434487819672\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.17366848513484\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.16682017222046852\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.16013477370142937\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.15356961637735367\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.14713968709111214\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.14082623273134232\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.13472754135727882\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.12880578264594078\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.1230833288282156\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.11754252016544342\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.11219213530421257\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.10709591209888458\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.1021483987569809\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.09741381742060184\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.09290605410933495\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.0885496698319912\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.08441983535885811\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.0804537832736969\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.07665490172803402\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.07305444031953812\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.06980678625404835\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.06723060831427574\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.0647823978215456\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.06241870205849409\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.060129993595182896\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.05791828315705061\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.05576602462679148\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.053713344037532806\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.051731367595493793\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.0498091634362936\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.047999381087720394\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.04618687927722931\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.044463044963777065\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94155\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94155\n",
      "ROC-AUC: 0.6893120886383403\n",
      "ROC_PR: 0.6371721041165003\n",
      "counter für die Anzhal der Files: 3\n",
      "##############Start Training with Dataset 11_donors.npz######################\n",
      "Die gesamte Länge der Daten ist 619326\n",
      "Die Länge das Anomalydatensatzen ist 36710 und der normalen daten ist: 582616\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1000 und 1000\n",
      "Die ungelabelden parts dazu sind 35710 und 581616\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 3000000 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 617326\n",
      "Die länge des ungelabendeten Datenloader ist: 2412\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3148.6082547947312\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2603.7724351880493\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1878.9764536481555\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1365.420578147458\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1347.9097506596943\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1386.008081509886\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1343.6397825283893\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1142.9900984976903\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 909.1630331443554\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 799.4690018904597\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 870.2308407394601\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 974.0765921316595\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 964.0642940971426\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 900.8571933486252\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 847.5094976984241\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 794.7535555257112\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 743.5152799578817\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 685.1640423962622\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 667.0882601119093\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 696.816574782863\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 2000\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2.154453694820404\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2.004082754254341\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.8501396626234055\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.6914395987987518\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.5252337604761124\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.387822449207306\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1.2692352533340454\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1.1546370089054108\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.048090361058712\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.9554145857691765\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8726510256528854\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7931730598211288\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7218460440635681\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6571387127041817\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6008896976709366\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.5578673407435417\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.5324416384100914\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.5133871510624886\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.49997011199593544\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.4959052540361881\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.4957980215549469\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.5018479935824871\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.5032647959887981\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.4964517876505852\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.4845356196165085\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.4791672118008137\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.48127223178744316\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.4832284487783909\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.4838020093739033\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.4822337254881859\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.4830925837159157\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.48444418609142303\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.4854258932173252\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.4857109859585762\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.4856228157877922\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.48626095801591873\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.4839271828532219\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.4837113544344902\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.48166103661060333\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.47897592931985855\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 617326\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 617326\n",
      "ROC-AUC: 0.9424164740997496\n",
      "ROC_PR: 0.34773548343119787\n",
      "counter für die Anzhal der Files: 4\n",
      "##############Start Training with Dataset 5_campaign.npz######################\n",
      "Die gesamte Länge der Daten ist 41188\n",
      "Die Länge das Anomalydatensatzen ist 4640 und der normalen daten ist: 36548\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 232 und 1000\n",
      "Die ungelabelden parts dazu sind 4408 und 35548\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1285824 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 39956\n",
      "Die länge des ungelabendeten Datenloader ist: 157\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1742.0511485302375\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1636.9188305085668\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1520.0592290964494\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1435.3644527167219\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1410.5543702216873\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1414.7720399735435\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1388.888090163665\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1339.4111399938213\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1315.6094041019708\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1312.0398479615837\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1304.2897317845723\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1295.875491416243\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1298.2548119956793\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1289.1884416401351\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1273.8126311715134\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1264.2111286859742\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1258.629733450736\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1255.003852396165\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1250.3393994923158\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1242.8099974370823\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1232\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.3406201362609864\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.2738011837005616\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.204775047302246\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.134973692893982\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.0680351734161377\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.002186620235443\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.9358715295791626\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.8735706090927124\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8132362604141236\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.7586734056472778\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.7063819289207458\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6583619236946106\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.616150176525116\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5790124773979187\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.5446933388710022\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.5181695938110351\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.49214677810668944\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.47207126021385193\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.45424106121063235\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.43946996331214905\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.4330268740653992\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.419726300239563\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.41456992030143736\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.4070893168449402\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.40291444659233094\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.4013416290283203\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.40385910868644714\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.39868966341018675\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.4021077036857605\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.40260780453681944\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.4008308708667755\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.4052837371826172\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.4130916893482208\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.4128239989280701\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.41452268362045286\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.4167711794376373\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.4204071700572968\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.43132227659225464\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.43045315742492674\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.4414668619632721\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 39956\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 39956\n",
      "ROC-AUC: 0.7648499239136183\n",
      "ROC_PR: 0.39148767042839616\n",
      "counter für die Anzhal der Files: 5\n",
      "##############Start Training with Dataset 10_cover.npz######################\n",
      "Die gesamte Länge der Daten ist 286048\n",
      "Die Länge das Anomalydatensatzen ist 2747 und der normalen daten ist: 283301\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 137 und 1000\n",
      "Die ungelabelden parts dazu sind 2610 und 282301\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1155769 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 284911\n",
      "Die länge des ungelabendeten Datenloader ist: 1113\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 600274.5239029623\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 85728.18392511074\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 77856.38838074474\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 34591.3282225481\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 13819.515928242663\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 11923.646088775264\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 9037.373147126766\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 11141.292990487438\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 8873.330532340116\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 8934.862956486191\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 4855.28942781873\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 5842.077173257112\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 4847.081710163171\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 3730.3696503733217\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 3653.8015348145072\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 3705.1119137380606\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 3069.3932693160386\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1363.0259844842278\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1161.420647956789\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1179.9700732800388\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1137\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7054827213287354\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7039765477180481\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.702701735496521\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.7011577367782593\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6995131015777588\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6977465867996215\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.6959637761116028\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6941093325614929\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.692270815372467\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.690373694896698\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6883036732673645\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6863609433174134\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6843896389007569\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6825552225112915\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6801486372947693\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6783979892730713\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.676295530796051\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6744166493415833\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6722324371337891\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6704806685447693\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6683037757873536\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6658506035804749\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6640899300575256\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6625447869300842\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6601989150047303\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6583107709884644\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6565100669860839\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6542062640190125\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.652447235584259\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6503570079803467\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6486110687255859\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6462648391723633\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6446825623512268\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6418632984161377\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6401647448539733\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.640013062953949\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6358768939971924\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.634723162651062\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6329400897026062\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6302965641021728\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 284911\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 284911\n",
      "ROC-AUC: 0.499437675291316\n",
      "ROC_PR: 0.009150554805489888\n",
      "counter für die Anzhal der Files: 6\n",
      "##############Start Training with Dataset 3_backdoor.npz######################\n",
      "Die gesamte Länge der Daten ist 95329\n",
      "Die Länge das Anomalydatensatzen ist 2329 und der normalen daten ist: 93000\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 116 und 1000\n",
      "Die ungelabelden parts dazu sind 2213 und 92000\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1129456 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94213\n",
      "Die länge des ungelabendeten Datenloader ist: 369\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 990.5151047624465\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 889.1612830140433\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 772.3922665372072\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 677.1073249408795\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 617.4008708618385\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 544.0092972230609\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 453.4936560858193\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 394.22140416813676\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 384.391966355463\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 381.29426759389565\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 307.82260582129305\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 273.1929502426659\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 276.12711814783535\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 259.3311915669999\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 265.35882552104545\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 258.28991883901284\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 245.22705318575433\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 229.77820206380173\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 213.93318976041738\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 207.82481885539977\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1116\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3.2453776359558106\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 3.087743043899536\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2.919455718994141\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2.7452673435211183\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 2.5499852180480955\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 2.3875144958496093\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2.218480348587036\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.0815898418426513\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.9077921152114867\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.7536417245864868\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.5924349308013916\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.4413399696350098\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1.287672472000122\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1.146817398071289\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1.018625557422638\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.8903292536735534\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7719171285629273\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.66634441614151\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.5763017177581787\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.4996748149394989\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.4424763977527618\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.3931725859642029\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.3480398952960968\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.3128236591815948\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.27628724575042723\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.24520330727100373\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.22448733747005462\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.19619354009628295\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.18162702918052673\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.1667136937379837\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.15260563790798187\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.14898902773857117\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.13251046538352967\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.13247896432876588\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.1155485525727272\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.11290948390960694\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.1193307727575302\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.10498431324958801\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.09883377924561501\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.1008526474237442\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94213\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94213\n",
      "ROC-AUC: 0.9618302938171673\n",
      "ROC_PR: 0.8525198196914966\n",
      "counter für die Anzhal der Files: 7\n",
      "##############Start Training with Dataset 22_magic.gamma.npz######################\n",
      "Die gesamte Länge der Daten ist 19020\n",
      "Die Länge das Anomalydatensatzen ist 6688 und der normalen daten ist: 12332\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 334 und 616\n",
      "Die ungelabelden parts dazu sind 6354 und 11716\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 696756 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 18070\n",
      "Die länge des ungelabendeten Datenloader ist: 71\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2825.2568918153875\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2722.573652347338\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2607.404669767964\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2492.294423996745\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 2391.060532479493\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 2318.275734233646\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2289.3089161017288\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2312.2127581056125\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2379.278385518317\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2436.253000857811\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 2400.5982101406794\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 2297.411355158058\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 2214.1498837327363\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 2173.9190370670403\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 2159.5362790547074\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 2152.6271798206026\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 2142.7371474132215\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 2126.433830804986\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 2104.6566998483854\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 2080.268511680362\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 950\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.6852488666772842\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6810214668512344\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.6776182949542999\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.6742214560508728\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6695654392242432\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6685553938150406\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.6656437814235687\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6633352041244507\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.6611350625753403\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.6596132963895798\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6569893211126328\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6552066057920456\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6517491638660431\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.650429293513298\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6524074077606201\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6474798768758774\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.64561727643013\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6436736136674881\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6401858180761337\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6367096453905106\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6381762772798538\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6339985281229019\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6333367973566055\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6302138119935989\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6264496147632599\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6267258375883102\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6268255710601807\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6220299303531647\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6198392957448959\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6211533844470978\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6180174052715302\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6160720884799957\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6157685071229935\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6170666068792343\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6147268265485764\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6129370182752609\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6119015514850616\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6124187111854553\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6112434715032578\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6099600940942764\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 18070\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 18070\n",
      "ROC-AUC: 0.6983855493344587\n",
      "ROC_PR: 0.6565636781656484\n",
      "counter für die Anzhal der Files: 8\n",
      "##############Start Training with Dataset 16_http.npz######################\n",
      "Die gesamte Länge der Daten ist 567498\n",
      "Die Länge das Anomalydatensatzen ist 2211 und der normalen daten ist: 565287\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 110 und 1000\n",
      "Die ungelabelden parts dazu sind 2101 und 564287\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1122100 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 566388\n",
      "Die länge des ungelabendeten Datenloader ist: 2213\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 805.5276499421057\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 625.5505591134955\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 453.79834967286047\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 307.7930804203897\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 204.32056995029868\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 143.4340050829588\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 102.52767924670755\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 85.12392753580191\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 76.60182472302095\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 77.93467388448924\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 95.16626699475476\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 134.36212864409399\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 191.72965999067264\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 253.80351487389447\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 266.12658714377966\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 274.5695266131937\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 320.90314530630184\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 391.4586747997869\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 421.1828201600235\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 363.549496688982\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1110\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.8449994802474976\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.6462940454483033\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.411944043636322\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.3731251955032349\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.2097434520721435\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.0049776554107666\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.852133285999298\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6298018097877502\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.5672728776931762\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.5768317639827728\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8543178319931031\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.3388733863830566\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1.864863109588623\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 2.15071382522583\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 2.0812330722808836\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1.6992498636245728\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1.1184442400932313\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6707875967025757\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.5473631799221039\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6274607300758361\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.8871277689933776\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1.0949976921081543\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1.254861044883728\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1.3978227972984314\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1.6462733745574951\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1.9104118824005127\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1.8688875436782837\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1.9922129392623902\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 2.08768835067749\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 2.17574405670166\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 2.086478066444397\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 2.1571566104888915\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 2.189617967605591\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 2.1787004232406617\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 2.2660261154174806\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 2.133805537223816\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 2.349465012550354\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 2.204027795791626\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 2.2640044689178467\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 2.3152591228485107\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 566388\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 566388\n",
      "ROC-AUC: 0.0033310947785356844\n",
      "ROC_PR: 0.003595251341808436\n",
      "counter für die Anzhal der Files: 9\n",
      "##############Start Training with Dataset 32_shuttle.npz######################\n",
      "Die gesamte Länge der Daten ist 49097\n",
      "Die Länge das Anomalydatensatzen ist 3511 und der normalen daten ist: 45586\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 175 und 1000\n",
      "Die ungelabelden parts dazu sind 3336 und 44586\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1205625 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 47922\n",
      "Die länge des ungelabendeten Datenloader ist: 188\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1219.8411446087425\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 284.422848096066\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 285.8140635747565\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 197.0097083713345\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 138.87830393602894\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 133.30481921153464\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 142.60077817131253\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 141.02023097987893\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 127.85588137065783\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 133.02724618152448\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 120.4620774585983\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 115.71084046920647\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 100.0885252914611\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 93.74497618427196\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 89.77202995395459\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 76.21397227887894\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 67.62605881167381\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 70.66317158026933\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 72.06631785698093\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 70.82620477568034\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1175\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7511242985725403\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7514538288116455\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7530763268470764\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.748878276348114\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.7523887991905213\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.7458057761192322\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7439118266105652\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.7442324042320252\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.7441466093063355\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.7378651618957519\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.73797607421875\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7343894124031067\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7349451184272766\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.731442105770111\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7315763711929322\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.7225952625274659\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7253062486648559\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.7224730610847473\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.7245331287384034\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.7166273117065429\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.7212818026542663\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.7129823327064514\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.713410758972168\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.7103072762489319\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.7103524565696716\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.7076688170433044\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.7045344829559326\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.7019135236740113\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.7007881879806519\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.7024823188781738\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6955316305160523\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6940481662750244\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6897292852401733\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6902300834655761\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6914694309234619\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6884399652481079\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6866060853004455\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.684450340270996\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6838780879974365\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6827691078186036\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 47922\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 47922\n",
      "ROC-AUC: 0.9738777037850275\n",
      "ROC_PR: 0.9147778325264352\n",
      "counter für die Anzhal der Files: 10\n",
      "##############Start Training with Dataset 13_fraud.npz######################\n",
      "Die gesamte Länge der Daten ist 284807\n",
      "Die Länge das Anomalydatensatzen ist 492 und der normalen daten ist: 284315\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 24 und 1000\n",
      "Die ungelabelden parts dazu sind 468 und 283315\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1024576 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 283783\n",
      "Die länge des ungelabendeten Datenloader ist: 1109\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 231.58333056422438\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 226.47799787822996\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 219.4026470428913\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 210.8522151591456\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 201.07954112732378\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 190.44802426239147\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 179.2600662950096\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 167.79786755518708\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 156.54309576301614\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 145.72656110718998\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 135.57932361518922\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 126.59689890584914\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 119.29605416825137\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 113.36267255575336\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 108.59476553187679\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 104.77961439053595\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 101.87155458339298\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 99.56411674646267\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 97.99856657389846\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 97.20005169291214\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1024\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.0717146685346961\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.07015964109450579\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.06937098503112793\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.06921789608895779\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.06892961356788874\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.06884278636425734\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.07014317438006401\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.07068529818207026\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.0698279608041048\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.0679757697507739\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.06696648709475994\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.06764966621994972\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.06908761756494641\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.071467449888587\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.0741248824633658\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.07578521640971303\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.07726670615375042\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.07703262008726597\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.07522394694387913\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.07261178456246853\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.06997236609458923\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.0674882922321558\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.06565157324075699\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.06691177934408188\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.0718074468895793\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.07698290981352329\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.08076296094805002\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.08360342681407928\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.08403592184185982\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.08178932964801788\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.07777983509004116\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.07378487847745419\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.07026065606623888\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.06818638369441032\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.06664894428104162\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.06593434000387788\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.06660416722297668\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.06739705707877874\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.06877728085964918\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.07037123292684555\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 283783\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 283783\n",
      "ROC-AUC: 0.9583789622284761\n",
      "ROC_PR: 0.7132043315712681\n",
      "counter für die Anzhal der Files: 11\n",
      "##############Start Training with Dataset 9_census.npz######################\n",
      "Die gesamte Länge der Daten ist 299285\n",
      "Die Länge das Anomalydatensatzen ist 18568 und der normalen daten ist: 280717\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 928 und 1000\n",
      "Die ungelabelden parts dazu sind 17640 und 279717\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 2789184 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 297357\n",
      "Die länge des ungelabendeten Datenloader ist: 1162\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2536.840546068816\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1924.001370445397\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1724.2281892751282\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1637.7160214775633\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1543.500116905627\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1526.013658330304\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1484.774423226736\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1463.6095655780182\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1451.5389774339314\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1430.1579538196895\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1407.6368580508688\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1392.1297005920858\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1365.6990316617857\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1336.2638821314786\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1302.6776035437674\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1276.5180549565566\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1255.5664390138243\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1227.4264228529516\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1198.8856494584272\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1164.7864475278252\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1928\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.008397437632084\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.9852162525057793\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.9631411358714104\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.9319907501339912\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.919588215649128\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.8995972499251366\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.8835146874189377\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.8615766018629074\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8440700992941856\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.8314107283949852\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8231025785207748\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.8112875148653984\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7856065630912781\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.7521212920546532\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7193983569741249\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6934346258640289\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6690342202782631\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6443501487374306\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.615205317735672\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.5881907418370247\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.5612820908427238\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.5346994698047638\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.5084661766886711\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.48427242413163185\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.4619766138494015\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.44669853150844574\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.4255581647157669\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.41221294552087784\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.3971256837248802\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.38489145413041115\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.3771093040704727\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.367673322558403\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.35897231101989746\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.3531140573322773\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.3452400602400303\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.33970676362514496\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.3352884016931057\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.3245573788881302\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.3208569884300232\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.31291065737605095\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 297357\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 297357\n",
      "ROC-AUC: 0.8960499028468172\n",
      "ROC_PR: 0.30433399815099405\n",
      "counter für die Anzhal der Files: 12\n",
      "##############Start Training with Dataset 1_ALOI.npz######################\n",
      "Die gesamte Länge der Daten ist 49534\n",
      "Die Länge das Anomalydatensatzen ist 1508 und der normalen daten ist: 48026\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 75 und 1000\n",
      "Die ungelabelden parts dazu sind 1433 und 47026\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1080625 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 48459\n",
      "Die länge des ungelabendeten Datenloader ist: 190\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 693.0758243811721\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 691.9054433984363\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 690.3427070895963\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 688.2149175682773\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 685.8297309748995\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 683.3244133302805\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 680.3354896317721\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 677.3406259309958\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 674.4898244802673\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 671.4257497457687\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 668.7700750223555\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 666.1641630048946\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 664.1370861246822\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 662.430896500624\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 661.5135058859748\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 661.019342664631\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 661.7006575251461\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 663.086800763642\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 665.4855229799242\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 667.7125234057247\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1075\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3.4469808101654054\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 3.3700042247772215\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 3.291650915145874\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 3.2306516647338865\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 3.131160306930542\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 3.0607667446136473\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2.980637788772583\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.929009437561035\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2.8383787631988526\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2.6881741523742675\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 2.6324674129486083\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 2.5763722896575927\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 2.5014894008636475\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 2.3951510906219484\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 2.321850538253784\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 2.2354844570159913\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 2.1266074180603027\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 2.0713006019592286\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1.9885618925094604\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1.8898756742477416\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1.8493731498718262\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1.7472356319427491\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1.6853896141052247\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1.586379313468933\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1.5535970211029053\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1.493868350982666\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1.4497551202774048\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1.396843433380127\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1.36480553150177\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1.3277604579925537\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 1.2903170585632324\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 1.263407301902771\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 1.2250319957733153\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 1.193580412864685\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 1.1581064224243165\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 1.1444575786590576\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 1.1134222745895386\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 1.0889219522476197\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 1.0603479146957397\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 1.029828667640686\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 48459\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 48459\n",
      "ROC-AUC: 0.4748277734082398\n",
      "ROC_PR: 0.0278381185239696\n"
     ]
    }
   ],
   "source": [
    "roc_all_lower_learning = []\n",
    "pr_all_lower_learning = []\n",
    "\n",
    "counter = 0\n",
    "for file in medium_files:\n",
    "    print(f'counter für die Anzhal der Files: {counter}')\n",
    "    roc, pr = train_dataset(file, \n",
    "                            random_seed=random_seed,\n",
    "                            percentage_labeld=0.05,\n",
    "                            contrastiv_margin=10.0,\n",
    "                            lr_siamese=0.00001,\n",
    "                            lr_classifier=0.0001,\n",
    "                            epochs_siamese=20,\n",
    "                            epochs_classifier=40,\n",
    "                            print_embeddeds=False,\n",
    "                            print_learning=False,\n",
    "                            )\n",
    "    \n",
    "    roc_all_lower_learning.append(roc)\n",
    "    pr_all_lower_learning.append(pr)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(roc_all_lower_learning)), roc_all_lower_learning, marker='o', color='b')\n",
    "plt.plot(range(len(pr_all_lower_learning)), pr_all_lower_learning, marker='x', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter für die Anzhal der Files: 0\n",
      "##############Start Training with Dataset 8_celeba.npz######################\n",
      "Die gesamte Länge der Daten ist 202599\n",
      "Die Länge das Anomalydatensatzen ist 4547 und der normalen daten ist: 198052\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 227 und 1000\n",
      "Die ungelabelden parts dazu sind 4320 und 197052\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1278529 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 201372\n",
      "Die länge des ungelabendeten Datenloader ist: 787\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1671.8359468843844\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1458.8312048132116\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1283.7850770692567\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1202.1724749529803\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1102.3621604148093\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1098.5412751496615\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1092.366843650291\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1075.8519124471152\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1035.9235147012246\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 997.2818555616163\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 973.770581225757\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 955.5180398415994\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 937.8194642518495\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 927.1144532105347\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 919.3976530852141\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 911.8291569890202\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 903.7989617913812\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 894.3214717158564\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 885.7836204735008\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 879.4756309898765\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 873.5826864095541\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 868.2660118981286\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 863.8541707601156\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 857.7140410918731\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 850.3852498372396\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 841.1295329020427\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 832.6629136521776\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 826.7624165425191\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 823.5900638370304\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 821.3626327316085\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1227\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.9368912220001221\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.9279330492019653\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.9179647326469421\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.9080596446990967\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.8986794948577881\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.8872725963592529\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.8758097410202026\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.8633476972579956\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8523207426071167\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.8406550526618958\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8282501101493835\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.8155593514442444\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.8019413828849793\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.7897465586662292\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7770067453384399\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.7646184086799621\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7522049427032471\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.7401569724082947\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.726769483089447\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.7146111369132996\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.7020928144454956\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.690298342704773\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.678419041633606\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6671356201171875\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.655535626411438\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6437548279762269\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6314978837966919\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6209585309028626\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6094976305961609\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.5993491888046265\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.5891321539878845\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.5782203435897827\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.5670198917388916\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.5576640367507935\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.5472863435745239\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.5376861453056335\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.5283902049064636\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.5190535902976989\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.5111212491989136\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.5018437504768372\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 201372\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 201372\n",
      "ROC-AUC: 0.9554845805647465\n",
      "ROC_PR: 0.28171844751004554\n",
      "counter für die Anzhal der Files: 1\n",
      "##############Start Training with Dataset 33_skin.npz######################\n",
      "Die gesamte Länge der Daten ist 245057\n",
      "Die Länge das Anomalydatensatzen ist 50859 und der normalen daten ist: 194198\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1000 und 1000\n",
      "Die ungelabelden parts dazu sind 49859 und 193198\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 3000000 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 243057\n",
      "Die länge des ungelabendeten Datenloader ist: 950\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3038.598897056863\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2580.3892920701023\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2178.9008788020856\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1967.7509794791044\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1605.9460316617412\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1240.2780887028578\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1221.0916122487304\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1406.833322055796\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1456.56679750207\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1299.8931333371138\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1096.073688469646\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1064.5047479976677\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1088.7305277643661\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1079.1823626304306\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1026.768574093336\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 965.0997291224454\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 975.0741795529195\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1004.4645268999886\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 988.4192199628908\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 963.9718990135502\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 937.8960496030252\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 886.1271190016696\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 824.5698318201503\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 789.6724617140459\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 790.6817780387352\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 761.2552227766016\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 769.3519260703688\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 742.2799761443631\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 682.9160472415131\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 648.762884329301\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 2000\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 5.63768994808197\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 5.299190640449524\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 4.825355887413025\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 4.379124253988266\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 3.814645767211914\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 3.3593916594982147\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2.889753997325897\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.404333770275116\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.913308709859848\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.4494237005710602\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.011958085000515\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6624315083026886\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.41949204728007317\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.28667413629591465\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.22742573358118534\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.2058658692985773\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.20270817168056965\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.2097499705851078\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.22531120479106903\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.24602673016488552\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.2697904706001282\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.29816296696662903\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.3268137313425541\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.3560508079826832\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.3869292885065079\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.4189772680401802\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.4484500326216221\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.4808368980884552\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.5129816494882107\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.5411422550678253\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.5692507922649384\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.5958003289997578\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6275523975491524\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6522249430418015\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.677518904209137\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.7023599818348885\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.72049480676651\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7390603125095367\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.7617105543613434\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.7773536667227745\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 243057\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 243057\n",
      "ROC-AUC: 0.9906813130999584\n",
      "ROC_PR: 0.9349593177422387\n",
      "counter für die Anzhal der Files: 2\n",
      "##############Start Training with Dataset 34_smtp.npz######################\n",
      "Die gesamte Länge der Daten ist 95156\n",
      "Die Länge das Anomalydatensatzen ist 30 und der normalen daten ist: 95126\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1 und 1000\n",
      "Die ungelabelden parts dazu sind 29 und 94126\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1001001 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94155\n",
      "Die länge des ungelabendeten Datenloader ist: 368\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 10.67149791721949\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 9.863097901647276\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 9.907438256892362\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 9.803634298141885\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 9.411709037423895\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 9.318051901369014\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 9.128165756694438\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 8.768279308127918\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 8.495123182876096\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 8.186159473258313\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 7.884704480430136\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 7.56567749653866\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 7.252103264276648\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 6.934633672669839\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 6.656527095181166\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 6.338145063834266\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 6.004612649755462\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 5.684036193982746\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 5.339984002941993\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 4.972405622689217\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 4.571035277190811\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 4.16154332965521\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 3.719206229283762\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 3.2861663925020217\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 2.8457069946488693\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 2.4313658049253437\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 2.040126258878376\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1.6896796503407407\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1.3708167984144397\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1.046549436920357\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1001\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.050378319807350636\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.046884228475391865\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.04348274413496256\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.04021723661571741\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.03700593486428261\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.03395108412951231\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.031064759474247694\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.028315826784819365\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.025762238074094057\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.023380647879093885\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.021182597614824772\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.019163290038704872\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.01731160841882229\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.01563026267103851\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.014100949978455901\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.012716809986159205\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.01146291196346283\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.010331112425774336\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.009308535372838378\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.008392464369535446\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.0075642261654138565\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.006818229798227549\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.006148076965473592\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.005546028725802898\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.005003368831239641\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.004516759538091719\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.004078370810020715\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.003696319239679724\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.0034090304980054498\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.003154942416585982\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.0029207842308096588\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.002703509002458304\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.002504036936443299\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.00231868150876835\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.0021480455179698765\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.0019898817990906537\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.0018437854596413672\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.001708474213955924\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.001583441800903529\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.0014674998528789729\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94155\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94155\n",
      "ROC-AUC: 0.6936659371480781\n",
      "ROC_PR: 0.6266440794350667\n",
      "counter für die Anzhal der Files: 3\n",
      "##############Start Training with Dataset 11_donors.npz######################\n",
      "Die gesamte Länge der Daten ist 619326\n",
      "Die Länge das Anomalydatensatzen ist 36710 und der normalen daten ist: 582616\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 1000 und 1000\n",
      "Die ungelabelden parts dazu sind 35710 und 581616\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 3000000 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 617326\n",
      "Die länge des ungelabendeten Datenloader ist: 2412\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 3148.6082547947312\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2603.7724351880493\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1878.9764536481555\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1365.420578147458\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1347.9097506596943\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1386.008081509886\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1343.6397825283893\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1142.9900984976903\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 909.1630331443554\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 799.4690018904597\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 870.2308407394601\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 974.0765921316595\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 964.0642940971426\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 900.8571933486252\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 847.5094976984241\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 794.7535555257112\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 743.5152799578817\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 685.1640423962622\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 667.0882601119093\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 696.816574782863\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 614.6812306493712\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 460.1583940428021\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 449.35251042899625\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 528.8739868783841\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 499.0221789018501\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 500.6271475922055\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 505.3484059058823\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 401.0116000337826\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 397.77875748937146\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 458.4932736500059\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 2000\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 5.567116618156433\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 5.185978591442108\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 4.7903441190719604\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 4.389847993850708\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 3.9337868094444275\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 3.4738159775733948\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 3.011722296476364\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.5386611223220825\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2.0589208751916885\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.629960522055626\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.286425843834877\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.9953343495726585\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7472852766513824\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5658985897898674\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.49458541348576546\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.4854351356625557\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.486435454338789\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.4919566363096237\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.4981788136065006\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.5006641298532486\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.5029418505728245\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.5047923661768436\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.5063861310482025\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.5075105205178261\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.5085571892559528\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.5087220072746277\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.508221410214901\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.5064564868807793\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.5053639784455299\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.5040141344070435\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.5018930993974209\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.49939966946840286\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.4988425783813\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.49732619896531105\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.49627961590886116\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.49638451635837555\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.49514565989375114\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.495271235704422\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.49427487328648567\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.4937555119395256\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 617326\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 617326\n",
      "ROC-AUC: 0.9983885869356509\n",
      "ROC_PR: 0.9765335112462277\n",
      "counter für die Anzhal der Files: 4\n",
      "##############Start Training with Dataset 5_campaign.npz######################\n",
      "Die gesamte Länge der Daten ist 41188\n",
      "Die Länge das Anomalydatensatzen ist 4640 und der normalen daten ist: 36548\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 232 und 1000\n",
      "Die ungelabelden parts dazu sind 4408 und 35548\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1285824 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 39956\n",
      "Die länge des ungelabendeten Datenloader ist: 157\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1742.0511485302375\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1636.9188305085668\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1520.0592290964494\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1435.3644527167219\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1410.5543702216873\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1414.7720399735435\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1388.888090163665\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1339.4111399938213\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1315.6094041019708\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1312.0398479615837\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1304.2897317845723\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1295.875491416243\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1298.2548119956793\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1289.1884416401351\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1273.8126311715134\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1264.2111286859742\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1258.629733450736\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1255.003852396165\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1250.3393994923158\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1242.8099974370823\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1234.7501546839617\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1228.1645618752373\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1223.1266576822786\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1219.2590622807936\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1216.3106412285713\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1213.8564751799925\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1210.9576035199022\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1208.3204902103644\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1204.4402231910944\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1200.4633832685079\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1232\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.338499116897583\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.2815723180770875\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.2244069576263428\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.1671655416488647\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.1056020975112915\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.0444359302520752\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.9845028996467591\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.9228092789649963\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8647030830383301\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.8093299984931945\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.7567195892333984\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7052663326263428\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6598354578018188\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.616346025466919\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.5783059597015381\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.5446962237358093\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.5170332312583923\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.48752577900886535\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.4652734279632568\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.44439515471458435\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.42552414536476135\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.4115830659866333\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.40101262331008913\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.3896527349948883\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.38115682601928713\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.3734327435493469\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.36808362007141116\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.37029067873954774\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.36429850459098817\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.36989896893501284\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.36502695083618164\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.36655962467193604\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.3748309135437012\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.37499822974205016\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.38049755692481996\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.3829836964607239\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.38814461827278135\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.3932848334312439\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.3992111384868622\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.3993589341640472\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 39956\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 39956\n",
      "ROC-AUC: 0.7774918883483021\n",
      "ROC_PR: 0.40499467377168397\n",
      "counter für die Anzhal der Files: 5\n",
      "##############Start Training with Dataset 10_cover.npz######################\n",
      "Die gesamte Länge der Daten ist 286048\n",
      "Die Länge das Anomalydatensatzen ist 2747 und der normalen daten ist: 283301\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 137 und 1000\n",
      "Die ungelabelden parts dazu sind 2610 und 282301\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1155769 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 284911\n",
      "Die länge des ungelabendeten Datenloader ist: 1113\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 600274.5239029623\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 85728.18392511074\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 77856.38838074474\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 34591.3282225481\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 13819.515928242663\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 11923.646088775264\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 9037.373147126766\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 11141.292990487438\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 8873.330532340116\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 8934.862956486191\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 4855.28942781873\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 5842.077173257112\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 4847.081710163171\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 3730.3696503733217\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 3653.8015348145072\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 3705.1119137380606\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 3069.3932693160386\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1363.0259844842278\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1161.420647956789\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1179.9700732800388\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1185.338056751475\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1185.3679402534087\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1185.3612998852566\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1185.3480181012835\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1185.3779006231398\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1185.3646193934173\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1185.3679395774934\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1185.3679399627651\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1185.3513372376908\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1185.361299249896\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1137\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.705535066127777\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.704128897190094\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7026087164878845\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.700992476940155\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.6994990944862366\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.6976861715316772\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.6959662914276123\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6941365957260132\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.6922529697418213\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.6903888821601868\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6883942127227783\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6862618923187256\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6843152165412902\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6824583768844604\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6802738428115844\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6782649517059326\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6762797951698303\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6740846753120422\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6722314357757568\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6702065825462341\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6683555722236634\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6661730170249939\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6644185304641723\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6619220018386841\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.660097599029541\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6592562437057495\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6558826565742493\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6544230818748474\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6525558590888977\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6501083374023438\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6487256288528442\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6465138912200927\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6450839281082154\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6419959187507629\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6411829710006713\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6379886031150818\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6369635105133057\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6352032423019409\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6332724452018738\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6306315422058105\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 284911\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 284911\n",
      "ROC-AUC: 0.5\n",
      "ROC_PR: 0.009160755463987\n",
      "counter für die Anzhal der Files: 6\n",
      "##############Start Training with Dataset 3_backdoor.npz######################\n",
      "Die gesamte Länge der Daten ist 95329\n",
      "Die Länge das Anomalydatensatzen ist 2329 und der normalen daten ist: 93000\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 116 und 1000\n",
      "Die ungelabelden parts dazu sind 2213 und 92000\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1129456 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94213\n",
      "Die länge des ungelabendeten Datenloader ist: 369\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 990.5151047624465\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 889.1612830140433\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 772.3922665372072\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 677.1073249408795\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 617.4008708618385\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 544.0092972230609\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 453.4936560858193\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 394.22140416813676\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 384.391966355463\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 381.29426759389565\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 307.82260582129305\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 273.1929502426659\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 276.12711814783535\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 259.3311915669999\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 265.35882552104545\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 258.28991883901284\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 245.22705318575433\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 229.77820206380173\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 213.93318976041738\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 207.82481885539977\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 207.06977263992738\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 212.83829191437874\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 220.98447793630288\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 226.55202313887457\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 225.24772779528703\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 220.10287057196996\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 214.19193027631218\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 208.5171339060108\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 203.44823602622785\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 197.48294945965003\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1116\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2.306857633590698\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2.203984022140503\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2.0906295776367188\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.9830267906188965\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.8820916652679442\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.7569490194320678\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1.6375890493392944\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1.5154841423034668\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.3928934335708618\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.2740441799163817\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.166989016532898\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.0494735836982727\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.9487924098968505\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.8457563638687133\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7543872833251953\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6807961225509643\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6169392347335816\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.5538204312324524\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.4994704186916351\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.45174541473388674\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.400872129201889\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.36468809843063354\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.32332085967063906\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.29234397411346436\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.2572500318288803\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.23258110582828523\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.21623384654521943\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.18871485590934753\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.16803508400917053\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.1551127165555954\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.1381375551223755\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.12635182440280915\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.12302284091711044\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.11165635287761688\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.1122726783156395\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.1025293692946434\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.08927183523774147\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.09006672203540803\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.09173433631658554\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.08422450497746467\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94213\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94213\n",
      "ROC-AUC: 0.9331973123244073\n",
      "ROC_PR: 0.8655632445088788\n",
      "counter für die Anzhal der Files: 7\n",
      "##############Start Training with Dataset 22_magic.gamma.npz######################\n",
      "Die gesamte Länge der Daten ist 19020\n",
      "Die Länge das Anomalydatensatzen ist 6688 und der normalen daten ist: 12332\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 334 und 616\n",
      "Die ungelabelden parts dazu sind 6354 und 11716\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 696756 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 18070\n",
      "Die länge des ungelabendeten Datenloader ist: 71\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2825.2568918153875\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2722.573652347338\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2607.404669767964\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2492.294423996745\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 2391.060532479493\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 2318.275734233646\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2289.3089161017288\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2312.2127581056125\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2379.278385518317\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2436.253000857811\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 2400.5982101406794\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 2297.411355158058\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 2214.1498837327363\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 2173.9190370670403\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 2159.5362790547074\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 2152.6271798206026\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 2142.7371474132215\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 2126.433830804986\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 2104.6566998483854\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 2080.268511680362\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 2058.21774352534\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 2041.2089752264535\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 2030.1963963785388\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 2023.1075608970311\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 2017.3312218278581\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 2011.8129945148185\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 2005.650284026494\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1999.9274662418632\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1997.0457128655114\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1993.6858470280497\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 950\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7651697099208832\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7490785121917725\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7349509596824646\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.7223580926656723\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.7112383395433426\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.694464236497879\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.6834135055541992\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6731449067592621\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.6613081246614456\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.6536293774843216\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.6493101119995117\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.6395125985145569\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.6374727636575699\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6352675706148148\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6311503499746323\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6316858679056168\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6335738599300385\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6326718330383301\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6323512494564056\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6373201161623001\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6360953003168106\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6414948999881744\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6443566530942917\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6453142315149307\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6447365880012512\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.649727001786232\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6516779661178589\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6508862972259521\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.655519500374794\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6525469869375229\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6537522375583649\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6514153629541397\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6500921845436096\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6457740217447281\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.639473631978035\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6374442428350449\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6367787569761276\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6308224648237228\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6242868453264236\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6218308806419373\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 18070\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 18070\n",
      "ROC-AUC: 0.7847638175461582\n",
      "ROC_PR: 0.7423677814338445\n",
      "counter für die Anzhal der Files: 8\n",
      "##############Start Training with Dataset 16_http.npz######################\n",
      "Die gesamte Länge der Daten ist 567498\n",
      "Die Länge das Anomalydatensatzen ist 2211 und der normalen daten ist: 565287\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 110 und 1000\n",
      "Die ungelabelden parts dazu sind 2101 und 564287\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1122100 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 566388\n",
      "Die länge des ungelabendeten Datenloader ist: 2213\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 805.5276499421057\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 625.5505591134955\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 453.79834967286047\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 307.7930804203897\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 204.32056995029868\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 143.4340050829588\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 102.52767924670755\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 85.12392753580191\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 76.60182472302095\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 77.93467388448924\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 95.16626699475476\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 134.36212864409399\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 191.72965999067264\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 253.80351487389447\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 266.12658714377966\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 274.5695266131937\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 320.90314530630184\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 391.4586747997869\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 421.1828201600235\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 363.549496688982\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 340.8688542372989\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 314.07041345373557\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 254.33322643363562\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 217.31125892861917\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 182.64412166428392\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 136.81976780578168\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 106.29307690154027\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 72.59413528442383\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 47.732288403667674\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 33.8512971953754\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1110\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.6031907320022583\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6044437408447265\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.5422646224498748\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.5314826488494873\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.5439483404159546\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.5146638929843903\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.5102296292781829\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.5168310046195984\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.5225188553333282\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.5199129700660705\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.5365242600440979\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.536338472366333\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.5266919493675232\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.5113599240779877\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.4929393410682678\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.4740463674068451\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.4427267134189606\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.42062673568725584\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.4129210114479065\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.4018978953361511\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.38338652849197385\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.37570991516113283\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.3735884606838226\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.37169179916381834\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.38566817045211793\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.37838263511657716\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.416113543510437\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.40658639669418334\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.42142093777656553\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.43452476263046264\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.4261449635028839\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.41338951587677003\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.4114342451095581\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.3835925400257111\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.3674534022808075\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.33826676607131956\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.341062068939209\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.3275420606136322\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.3306433856487274\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.3274222195148468\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 566388\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 566388\n",
      "ROC-AUC: 0.9928895354775933\n",
      "ROC_PR: 0.38771460052031786\n",
      "counter für die Anzhal der Files: 9\n",
      "##############Start Training with Dataset 32_shuttle.npz######################\n",
      "Die gesamte Länge der Daten ist 49097\n",
      "Die Länge das Anomalydatensatzen ist 3511 und der normalen daten ist: 45586\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 175 und 1000\n",
      "Die ungelabelden parts dazu sind 3336 und 44586\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1205625 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 47922\n",
      "Die länge des ungelabendeten Datenloader ist: 188\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1219.8411446087425\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 284.422848096066\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 285.8140635747565\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 197.0097083713345\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 138.87830393602894\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 133.30481921153464\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 142.60077817131253\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 141.02023097987893\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 127.85588137065783\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 133.02724618152448\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 120.4620774585983\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 115.71084046920647\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 100.0885252914611\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 93.74497618427196\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 89.77202995395459\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 76.21397227887894\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 67.62605881167381\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 70.66317158026933\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 72.06631785698093\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 70.82620477568034\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 68.98555135998218\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 67.41258615736243\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 66.68537074529314\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 66.21214864174904\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 65.3655950040068\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 68.24485936154733\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 66.27657712518916\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 68.10115665359672\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 70.07753932278548\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 70.37631188468927\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1175\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7598062753677368\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7560054779052734\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7563059091567993\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.752681040763855\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.7527086019515992\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.7436533451080323\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7466134786605835\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.743899917602539\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.7463491678237915\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.7386111855506897\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.7437265872955322\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7355400800704956\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7363589882850647\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.7335686802864074\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7338975310325623\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.7315615892410279\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7286026000976562\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.7262477040290832\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.725420880317688\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.7274705171585083\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.7205042004585266\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.7191639900207519\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.7148065328598022\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.7156664848327636\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.7170145392417908\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.7140795588493347\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.7122108817100525\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.7100241541862488\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.709378433227539\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.7083477258682251\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.7039926767349243\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.7011221766471862\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.7026588082313537\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6976205229759216\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6975441813468933\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6958517909049988\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6909706592559814\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6900433540344239\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.6889887571334838\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6842419385910035\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 47922\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 47922\n",
      "ROC-AUC: 0.9731085270392219\n",
      "ROC_PR: 0.9049713078256219\n",
      "counter für die Anzhal der Files: 10\n",
      "##############Start Training with Dataset 13_fraud.npz######################\n",
      "Die gesamte Länge der Daten ist 284807\n",
      "Die Länge das Anomalydatensatzen ist 492 und der normalen daten ist: 284315\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 24 und 1000\n",
      "Die ungelabelden parts dazu sind 468 und 283315\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1024576 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 283783\n",
      "Die länge des ungelabendeten Datenloader ist: 1109\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 231.58333056422438\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 226.47799787822996\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 219.4026470428913\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 210.8522151591456\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 201.07954112732378\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 190.44802426239147\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 179.2600662950096\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 167.79786755518708\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 156.54309576301614\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 145.72656110718998\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 135.57932361518922\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 126.59689890584914\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 119.29605416825137\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 113.36267255575336\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 108.59476553187679\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 104.77961439053595\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 101.87155458339298\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 99.56411674646267\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 97.99856657389846\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 97.20005169291214\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 97.2518912869753\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 98.1556229080345\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 99.6692092339456\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 101.63333356401309\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 103.4846804578573\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 105.53398889927098\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 106.5032718995795\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 106.35491141253283\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 106.0450418507073\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 106.12664360181707\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1024\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.10662861354649067\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.10178129561245441\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.09714478114619851\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.09279495198279619\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.08847844181582332\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.08479709550738335\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.08010580996051431\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.07668615505099297\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.07409404404461384\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.07274129521101713\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.07063276506960392\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.06775995716452599\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.06518049165606499\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.06469007954001427\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.06470317579805851\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.06498382799327374\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.06572354771196842\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.06704736687242985\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.06832997594028711\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.06990505754947662\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.07139064744114876\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.07246788591146469\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.07317027635872364\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.07326401770114899\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.07268273178488016\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.07143331132829189\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.06996499560773373\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.06817631144076586\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.06662852317094803\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.06541685294359922\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.06459859386086464\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.06424380745738745\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.06503106653690338\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.06600015237927437\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.06703128572553396\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.06854759715497494\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.07017357833683491\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.07175218523479998\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.07336346805095673\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.07479989249259233\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 283783\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 283783\n",
      "ROC-AUC: 0.9699502237776775\n",
      "ROC_PR: 0.7255237328931433\n",
      "counter für die Anzhal der Files: 11\n",
      "##############Start Training with Dataset 9_census.npz######################\n",
      "Die gesamte Länge der Daten ist 299285\n",
      "Die Länge das Anomalydatensatzen ist 18568 und der normalen daten ist: 280717\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 928 und 1000\n",
      "Die ungelabelden parts dazu sind 17640 und 279717\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 2789184 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 297357\n",
      "Die länge des ungelabendeten Datenloader ist: 1162\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2536.840546068816\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1924.001370445397\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1724.2281892751282\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1637.7160214775633\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1543.500116905627\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1526.013658330304\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1484.774423226736\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1463.6095655780182\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1451.5389774339314\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1430.1579538196895\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1407.6368580508688\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1392.1297005920858\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1365.6990316617857\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1336.2638821314786\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1302.6776035437674\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1276.5180549565566\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1255.5664390138243\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1227.4264228529516\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1198.8856494584272\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1164.7864475278252\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1136.6983060290636\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1116.4618476722035\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1095.343289340295\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1065.5153213422554\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1033.049743489897\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1005.4370310163008\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 980.8572779640052\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 957.8513923622613\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 935.9681800528595\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 913.9265925145535\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1928\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.2069525197148323\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.1128928661346436\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.0145030692219734\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.91172906011343\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.8211664855480194\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.7535791471600533\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7117215767502785\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.6997939348220825\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.7263199687004089\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.7772990390658379\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8466253578662872\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.9251439198851585\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1.0101699605584145\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1.0671258866786957\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1.1090168580412865\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1.1162655800580978\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1.0944988876581192\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1.0404285714030266\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.9660648852586746\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.8802430555224419\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.7975597754120827\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.737918496131897\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.7034601792693138\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.7029767334461212\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.7312846332788467\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.7903508692979813\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.8595130816102028\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.9322396516799927\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1.0061167925596237\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1.073188677430153\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 1.1107337772846222\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 1.148272305727005\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 1.1703843474388123\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 1.1541698276996613\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 1.1276888623833656\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 1.0827991515398026\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 1.0339222624897957\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.9736719056963921\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.9045576453208923\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.8414606675505638\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 297357\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 297357\n",
      "ROC-AUC: 0.8858922433563946\n",
      "ROC_PR: 0.2951411175885466\n",
      "counter für die Anzhal der Files: 12\n",
      "##############Start Training with Dataset 1_ALOI.npz######################\n",
      "Die gesamte Länge der Daten ist 49534\n",
      "Die Länge das Anomalydatensatzen ist 1508 und der normalen daten ist: 48026\n",
      "Es werden 5.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 75 und 1000\n",
      "Die ungelabelden parts dazu sind 1433 und 47026\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1080625 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 48459\n",
      "Die länge des ungelabendeten Datenloader ist: 190\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 693.0758243811721\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 691.9054433984363\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 690.3427070895963\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 688.2149175682773\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 685.8297309748995\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 683.3244133302805\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 680.3354896317721\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 677.3406259309958\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 674.4898244802673\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 671.4257497457687\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 668.7700750223555\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 666.1641630048946\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 664.1370861246822\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 662.430896500624\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 661.5135058859748\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 661.019342664631\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 661.7006575251461\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 663.086800763642\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 665.4855229799242\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 667.7125234057247\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 670.8822024845501\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 674.0605822065779\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 676.562876915943\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 674.5508784479804\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 669.046558479515\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 664.4503676081539\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 661.1569574772606\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 658.9583736222709\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 657.3766536956599\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 656.6052621672471\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1075\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2.5455112934112547\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2.5293459415435793\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2.490679311752319\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2.419119644165039\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 2.380317544937134\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 2.322070360183716\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2.2401788234710693\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.210288667678833\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2.1507961750030518\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2.067838430404663\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 2.052320623397827\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.9627939462661743\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1.91923246383667\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1.828223204612732\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1.8013904571533204\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1.7367460012435914\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1.6890125036239625\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1.6284413814544678\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1.5802005290985108\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1.5219325065612792\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1.4639293670654296\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1.4194714307785035\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1.359872317314148\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1.3135879755020141\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1.2692853450775146\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1.2515350580215454\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1.2128607749938964\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1.1830580949783325\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1.1483497142791748\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1.118386483192444\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 1.0980284929275512\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 1.0763515949249267\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 1.0516543865203858\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 1.0335434436798097\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 1.0142121315002441\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.997977900505066\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.9694917559623718\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.9610197186470032\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.9384813070297241\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.917396092414856\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 48459\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 48459\n",
      "ROC-AUC: 0.47851319290669303\n",
      "ROC_PR: 0.028013565462190113\n"
     ]
    }
   ],
   "source": [
    "roc_all_more_ep = []\n",
    "pr_all_more_ep = []\n",
    "\n",
    "counter = 0\n",
    "for file in medium_files:\n",
    "    print(f'counter für die Anzhal der Files: {counter}')\n",
    "    roc, pr = train_dataset(file, \n",
    "                            random_seed=random_seed,\n",
    "                            percentage_labeld=0.05,\n",
    "                            contrastiv_margin=10.0,\n",
    "                            lr_siamese=0.00001,\n",
    "                            lr_classifier=0.0001,\n",
    "                            epochs_siamese=30,\n",
    "                            epochs_classifier=40,\n",
    "                            print_embeddeds=False,\n",
    "                            print_learning=False,\n",
    "                            )\n",
    "    \n",
    "    roc_all_more_ep.append(roc)\n",
    "    pr_all_more_ep.append(pr)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(roc_all_more_ep)), roc_all_more_ep, marker='o', color='b')\n",
    "plt.plot(range(len(pr_all_more_ep)), pr_all_more_ep, marker='x', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter für die Anzhal der Files: 0\n",
      "##############Start Training with Dataset 8_celeba.npz######################\n",
      "Die gesamte Länge der Daten ist 202599\n",
      "Die Länge das Anomalydatensatzen ist 4547 und der normalen daten ist: 198052\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 45 und 1000\n",
      "Die ungelabelden parts dazu sind 4502 und 197052\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1047025 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 201554\n",
      "Die länge des ungelabendeten Datenloader ist: 788\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 413.1417749903896\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 391.19893925860345\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 372.86936787089974\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 362.2000283873169\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 355.02525703784596\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 345.63254345844894\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 339.3504270483637\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 333.2347179216977\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 327.12423208185396\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 322.4599897557191\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 318.5680141365033\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 315.08692773571806\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 310.835509808081\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 306.05434192946603\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 300.4699342592421\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 295.7336434361987\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 291.5286666608964\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 287.2586787795088\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 283.1022173408191\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 278.91370953883984\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 274.0269969632398\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 267.8899492007304\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 262.4044058671499\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 257.25946232019254\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 252.61850641712292\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 248.15839621303718\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 243.57371571734365\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 238.51120170835762\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 232.69150315636819\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 226.81622716815082\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1045\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.6935633301734925\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.6608203768730163\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.6296373128890991\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.5987357020378112\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.5784582734107971\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.5368929505348206\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.5095340073108673\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.49108555912971497\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.4682383298873901\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.4452069938182831\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.41185944676399233\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.3900652050971985\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.372128826379776\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.35435912013053894\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.33505609035491946\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.32390653192996977\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.3780180811882019\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.2950736939907074\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.2869161754846573\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.3238429367542267\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.3140090584754944\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.29656009674072265\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.2949284493923187\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.29521549940109254\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.2883023858070374\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.2599194675683975\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.25625099390745165\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.3546691328287125\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.33639744222164153\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.28884667754173277\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.34794222116470336\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.2892760425806046\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.29391140639781954\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.3306264251470566\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.33206956684589384\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.2493126645684242\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.3124203681945801\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.32789313793182373\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.30028238892555237\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.4086596190929413\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 201554\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 201554\n",
      "ROC-AUC: 0.12171703952690918\n",
      "ROC_PR: 0.011980398025804051\n",
      "counter für die Anzhal der Files: 1\n",
      "##############Start Training with Dataset 33_skin.npz######################\n",
      "Die gesamte Länge der Daten ist 245057\n",
      "Die Länge das Anomalydatensatzen ist 50859 und der normalen daten ist: 194198\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 508 und 1000\n",
      "Die ungelabelden parts dazu sind 50351 und 193198\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1766064 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 243549\n",
      "Die länge des ungelabendeten Datenloader ist: 952\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2702.3156247805955\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2494.7207516771\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2286.124955411337\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2110.3494875170145\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1983.0539646328386\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1834.2449203780948\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1610.0549502900103\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1402.179195104915\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1286.0513861960717\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1291.9316637509455\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1407.1745034663086\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1538.6426594196878\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1573.1755475576313\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1431.9442915346228\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1245.7289741627806\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1150.9947184816895\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1126.5189093354647\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1141.7667680887714\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1156.841654730942\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1142.6157198606115\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1092.2884823431018\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1032.9364990552865\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 985.1241214440895\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 960.2088122043701\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 959.8318324234887\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 980.5838787600275\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1006.2121231426345\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1017.2808362101279\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1010.9018192493081\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 977.63502210713\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1508\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 5.024551868438721\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 4.7845165729522705\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 4.522250652313232\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 4.169123450915019\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 3.8495024045308432\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 3.511558492978414\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 3.167247454325358\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2.819072882334391\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2.468468348185221\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2.1313793659210205\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.809464693069458\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.5033223231633503\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1.226987401644389\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.9905711015065511\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7861536939938863\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.624311645825704\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.5021942853927612\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.4138662318388621\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.35126984616120654\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.3089919239282608\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.2787666271130244\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.25825335085392\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.24328249941269556\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.23487821966409683\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.2277259255448977\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.2239428013563156\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.22162188837925592\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.2209369863073031\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.22261295715967813\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.2240768770376841\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.22672285636266074\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.22965317716201147\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.2332951451341311\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.2388355831305186\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.24328531076510748\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.24947188049554825\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.2551579674084981\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.2600834419329961\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.2654758195082347\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.27021225293477374\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 243549\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 243549\n",
      "ROC-AUC: 0.9871081406830452\n",
      "ROC_PR: 0.8894858871230875\n",
      "counter für die Anzhal der Files: 2\n",
      "##############Start Training with Dataset 34_smtp.npz######################\n",
      "Die gesamte Länge der Daten ist 95156\n",
      "Die Länge das Anomalydatensatzen ist 30 und der normalen daten ist: 95126\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 5 und 951\n",
      "Die ungelabelden parts dazu sind 25 und 94175\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 909181 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94200\n",
      "Die länge des ungelabendeten Datenloader ist: 368\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 48.568895776193955\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 45.14974204501188\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 43.30660120015209\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 41.223993114455865\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 38.795780180877934\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 36.61583151587763\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 34.58597556246562\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 32.554132891835664\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 30.79422310803522\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 29.38859202393943\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 28.308823990660745\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 27.408944679038214\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 26.537892845601917\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 25.744202291576176\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 24.969624135089486\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 24.343714265488423\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 23.812366024381273\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 23.31105974482305\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 23.09610296781217\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 23.06743396570285\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 23.194293830824833\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 23.358076600181693\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 23.30137588819573\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 22.78171165303436\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 22.35553917459942\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 22.016579845047616\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 21.916259614264106\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 21.974498445335943\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 22.007494038205827\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 22.11053620733589\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 956\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.04086471349000931\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.03829956613481045\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.035894136410206556\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.03358419379219413\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.03272533696144819\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.030646266881376505\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.028789437375962734\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.025618817191570997\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.023995370604097843\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.024059760849922895\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.02125844545662403\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.021687834756448865\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.019062154227867723\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.018153824377804995\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.019158523995429277\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.018510715919546783\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.016196979209780693\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.015639959718100727\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.015332128154113889\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.015005804947577417\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.014684796275105327\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.014475635543931276\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.014286486897617579\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.01636538124876097\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.014170443871989846\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.01415079302387312\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.014132507174508646\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.01408220556913875\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.016450644005089998\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.014160253340378404\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.014226722880266607\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.014281565236160532\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.01689334085676819\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.016996773600112647\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.014555440953699872\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.017287489434238523\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.014820708878687583\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.014984032619395293\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.015062479564221576\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.017896746561746113\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94200\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94200\n",
      "ROC-AUC: 0.8526649323068755\n",
      "ROC_PR: 0.6323840763233263\n",
      "counter für die Anzhal der Files: 3\n",
      "##############Start Training with Dataset 11_donors.npz######################\n",
      "Die gesamte Länge der Daten ist 619326\n",
      "Die Länge das Anomalydatensatzen ist 36710 und der normalen daten ist: 582616\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 367 und 1000\n",
      "Die ungelabelden parts dazu sind 36343 und 581616\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1501689 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 617959\n",
      "Die länge des ungelabendeten Datenloader ist: 2414\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2376.882882837139\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2242.212975216855\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2044.4574590371487\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1811.4824365459122\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1584.5749268660236\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1411.5741486105544\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1336.2306361440665\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1321.9057130862373\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1285.274215973972\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1232.6620166569166\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1151.844700727128\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1025.0751586976492\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 905.1768597701366\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 854.6790205457696\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 869.2370710974458\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 905.7709627564434\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 922.6970682023858\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 926.6802263178599\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 922.5310584457507\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 910.7946961302421\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 884.3823653597333\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 840.270643554854\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 776.8436483857253\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 713.8996452438194\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 673.9778657348091\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 655.3129639077666\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 662.5087777107517\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 684.4272335974624\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 701.9771354251293\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 706.3137248598835\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1367\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.1836304465929668\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.1121226747830708\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.0812983810901642\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.0186991095542908\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.9781835476557413\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.9137208759784698\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.884464830160141\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.8553508619467417\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8133555154005686\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.8061710198720297\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.7593356569608053\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7467322647571564\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.718752125898997\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.6936370134353638\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.6782940030097961\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6603494981924692\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6454445719718933\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.633278489112854\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.628814289967219\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.633188913265864\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.643752247095108\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6528427302837372\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6611839135487875\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6682502826054891\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6733656823635101\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6785213152567545\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6810773114363352\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6852431893348694\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6854024728139242\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6877897381782532\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6882511874039968\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6897102693716685\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6896481513977051\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6891672710577647\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6901038487752279\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6896256804466248\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6905647615591685\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.689808170000712\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.68893763422966\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.689574658870697\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 617959\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 617959\n",
      "ROC-AUC: 0.9962863319168829\n",
      "ROC_PR: 0.9569699445579521\n",
      "counter für die Anzhal der Files: 4\n",
      "##############Start Training with Dataset 5_campaign.npz######################\n",
      "Die gesamte Länge der Daten ist 41188\n",
      "Die Länge das Anomalydatensatzen ist 4640 und der normalen daten ist: 36548\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 46 und 365\n",
      "Die ungelabelden parts dazu sind 4594 und 36183\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 152131 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 40777\n",
      "Die länge des ungelabendeten Datenloader ist: 160\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1088.5088437889804\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1081.9761452041755\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1076.3769573307839\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1069.8288974281118\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1063.3309802143513\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1056.596992146468\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1048.3769306599593\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1040.910570571002\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1033.79517165753\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1024.660113781841\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1016.3301710625657\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1007.0943687118402\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 999.2839619612494\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 990.2931323652508\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 982.3969459854254\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 973.3113273043592\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 965.255287593553\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 956.7833921288242\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 949.3806004628414\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 942.4211084189535\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 935.7747300091912\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 929.5836448861771\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 923.3264096043691\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 917.9368499499409\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 912.9761772091649\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 908.645130215172\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 904.2103718733587\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 901.6325239421941\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 899.2536270782728\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 897.7107393152573\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 411\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.4888906478881836\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.4851646423339844\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.4702113270759583\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.4461599588394165\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.4490578174591064\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 1.4364609718322754\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 1.4041840434074402\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 1.3968175053596497\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 1.3754312992095947\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 1.3634130954742432\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 1.3532280921936035\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 1.3387282490730286\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 1.3137127757072449\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 1.30500990152359\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 1.290889024734497\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 1.271510660648346\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 1.2501275539398193\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 1.2437484860420227\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 1.2185718417167664\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 1.2046759724617004\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1.190891981124878\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1.1789473295211792\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1.156493365764618\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 1.1446933150291443\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 1.1357063055038452\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 1.115755021572113\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 1.0985527038574219\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 1.0878403782844543\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 1.0746495127677917\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 1.0575572848320007\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 1.0383196473121643\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 1.0256515145301819\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 1.0113630294799805\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.99737149477005\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.978571891784668\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.9685114622116089\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.9531495869159698\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.9413245022296906\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.9280274212360382\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.9147667288780212\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 40777\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 40777\n",
      "ROC-AUC: 0.4034502224585128\n",
      "ROC_PR: 0.08800868393417542\n",
      "counter für die Anzhal der Files: 5\n",
      "##############Start Training with Dataset 10_cover.npz######################\n",
      "Die gesamte Länge der Daten ist 286048\n",
      "Die Länge das Anomalydatensatzen ist 2747 und der normalen daten ist: 283301\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 27 und 1000\n",
      "Die ungelabelden parts dazu sind 2720 und 282301\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1027729 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 285021\n",
      "Die länge des ungelabendeten Datenloader ist: 1114\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 739125.2592699253\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 103805.54369940847\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 90900.736379203\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 62565.852600112856\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 18448.30290171622\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 16544.574515002336\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 11467.51830367567\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 10363.40855665765\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 12933.221459079234\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 10053.750899215831\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 10007.264699637102\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 6440.099693532067\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 6437.477566547323\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 4796.384228272396\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 5160.512635174249\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 4280.0373033497435\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 3771.435014660599\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 3626.019096691849\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 4376.868385339644\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 2673.8264413417946\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 3610.6111891503056\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 4639.679924465384\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 3556.0325530359783\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 2710.170156225677\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 3139.184906879962\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 3798.427978029168\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 3983.16331715661\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 3427.4782703594433\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 4015.3618617075613\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 4504.397377601329\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1027\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 4.275612831115723\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 3.571687030792236\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2.9412044525146483\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2.364273929595947\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.632054591178894\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.9993311285972595\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7589952707290649\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.5605725586414337\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.25321570262312887\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.1856251336634159\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.15522777419537306\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.15478588342666627\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.16716710668988527\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.18290017975959927\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.20099595803767442\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.2211929837902062\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.24200315475782191\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.2645260355180653\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.2854477922317528\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.3061138510707451\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.32335480848950054\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.34096813996633274\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.35805794215557396\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.3714601874351516\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.38700607816378285\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.40072987079620503\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.41322742899259024\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.42498775720596316\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.43609151244163513\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.4463633418083191\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.45645942687988283\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.46767647862434386\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.477898496389389\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 2.1815425753593445\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.500961446762085\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.5098035335540771\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.5178151369094849\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.5269626021385193\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.5360340595245361\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.545844566822052\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 285021\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 285021\n",
      "ROC-AUC: 0.3398437703487954\n",
      "ROC_PR: 0.006494907523488548\n",
      "counter für die Anzhal der Files: 6\n",
      "##############Start Training with Dataset 3_backdoor.npz######################\n",
      "Die gesamte Länge der Daten ist 95329\n",
      "Die Länge das Anomalydatensatzen ist 2329 und der normalen daten ist: 93000\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 23 und 930\n",
      "Die ungelabelden parts dazu sind 2306 und 92070\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 886819 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 94376\n",
      "Die länge des ungelabendeten Datenloader ist: 369\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 235.33061272759974\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 221.78766542354876\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 208.00039446391756\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 192.91553161588067\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 177.86946863364346\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 165.0915943987958\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 151.9431739504375\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 137.90383095514207\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 123.37158760907502\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 110.3860860788805\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 98.07036530741021\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 83.48177196012774\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 69.79985777096658\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 58.87633493651904\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 50.18905597139059\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 44.31517788321425\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 41.60586423942709\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 42.285781567230885\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 44.80828286758577\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 46.976416745399156\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 46.855751634022546\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 43.778396874657616\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 40.18361464406849\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 39.20063435326063\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 40.30735076640075\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 41.377563917757286\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 41.19782452638359\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 40.74471045820228\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 41.34173554706711\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 42.94178035145714\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 953\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 11.401724338531494\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 11.051889181137085\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 10.68961501121521\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 10.308812379837036\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 9.885549306869507\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 9.456806421279907\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 9.042157649993896\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 8.581237554550171\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 8.114063382148743\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 7.638073801994324\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 7.134739875793457\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 6.636881589889526\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 6.12772262096405\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 5.610345482826233\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 5.077141642570496\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 4.539760947227478\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 4.005073547363281\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 3.464251399040222\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 2.9278484582901\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 2.4042978286743164\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 1.9037855565547943\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 1.4385853707790375\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 1.0323092490434647\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.7021687477827072\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.454861544072628\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.28472406044602394\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.1764478124678135\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.11179078929126263\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.07498888298869133\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.05389312654733658\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.041370843537151814\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.03707656404003501\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.03688783152028918\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.03505159402266145\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.03516367170959711\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.039310317719355226\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.03855404304340482\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.040753524051979184\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.037577349808998406\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.045469879056327045\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 94376\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 94376\n",
      "ROC-AUC: 0.9093236805285319\n",
      "ROC_PR: 0.8630059053057025\n",
      "counter für die Anzhal der Files: 7\n",
      "##############Start Training with Dataset 22_magic.gamma.npz######################\n",
      "Die gesamte Länge der Daten ist 19020\n",
      "Die Länge das Anomalydatensatzen ist 6688 und der normalen daten ist: 12332\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 66 und 123\n",
      "Die ungelabelden parts dazu sind 6622 und 12209\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 27603 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 18831\n",
      "Die länge des ungelabendeten Datenloader ist: 74\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 2857.5932187680846\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 2855.6177209924767\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 2853.456488715278\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 2849.864513255932\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 2846.2005490903503\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 2843.1776529947915\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 2839.9678435149017\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 2836.1815072518807\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 2833.0774140534577\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 2830.525831434462\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 2827.579418041088\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 2823.1043226453994\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 2819.164358633536\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 2816.200064199942\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 2811.8831922743057\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 2808.6449901439523\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 2805.5037502712676\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 2801.581436722367\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 2796.7943589952256\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 2793.7225138346353\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 2790.145376699942\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 2785.1457790798613\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 2781.394853379991\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 2777.3091283727576\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 2774.476634837963\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 2769.9394033926505\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 2766.3551364474824\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 2761.956662778501\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 2757.8356504087096\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 2754.2307445384836\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 189\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.7026352286338806\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.7024500370025635\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.7022712826728821\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.7020928859710693\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.7019137740135193\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.7017343044281006\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.7015541195869446\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.7013723254203796\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.7011883854866028\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.7010025382041931\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.700813889503479\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.7006231546401978\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7004305720329285\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.7002352476119995\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7000380158424377\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.6998385787010193\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.6996375918388367\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.6994344592094421\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.6992295384407043\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.6990225315093994\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.6988140940666199\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.6986050605773926\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.6983941197395325\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.6981807947158813\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.6979665160179138\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.6977514624595642\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.6975349187850952\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.6973167061805725\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.6970975399017334\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.6968767642974854\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.6966544985771179\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.6964322924613953\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.6962094306945801\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.6959856152534485\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.6957610249519348\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.6955353021621704\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.6953087449073792\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.6950811743736267\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.694852352142334\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.6946218609809875\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 18831\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 18831\n",
      "ROC-AUC: 0.3894003905947059\n",
      "ROC_PR: 0.2862496523649011\n",
      "counter für die Anzhal der Files: 8\n",
      "##############Start Training with Dataset 16_http.npz######################\n",
      "Die gesamte Länge der Daten ist 567498\n",
      "Die Länge das Anomalydatensatzen ist 2211 und der normalen daten ist: 565287\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 22 und 1000\n",
      "Die ungelabelden parts dazu sind 2189 und 564287\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1022484 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 566476\n",
      "Die länge des ungelabendeten Datenloader ist: 2213\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 180.46624915525223\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 146.21149303671416\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 114.50454140497239\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 85.23702098072992\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 59.77043155555582\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 40.9854896669543\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 30.430090355425513\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 29.397657454088424\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 37.852599252120726\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 49.9902256589658\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 64.52885547394447\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 81.26081025716807\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 96.8844254284836\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 106.3379955573434\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 99.10943848152782\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 87.14271416884937\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 75.83679318577238\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 64.1708408904762\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 51.7481999307759\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 37.526258520190794\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 26.73464272514601\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 27.93819254611401\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 37.87702850036239\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 43.808259676335304\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 46.276365322404274\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 45.50084073683795\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 42.84270775142092\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 38.231008348238184\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 33.670001449393986\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 30.503565742674102\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1022\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.1485525220632553\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.14715669304132462\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.14527317136526108\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.14454411529004574\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.14318387024104595\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.1422654502093792\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.14217804186046124\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.14224780350923538\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.1436362098902464\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.1455727070569992\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.1464480198919773\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.14646286517381668\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.14545727521181107\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.14374954625964165\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.1423742100596428\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.1404375284910202\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.1396949701011181\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.13966314028948545\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.1424185372889042\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.14608142152428627\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.14743433333933353\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.15126563794910908\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.15337464958429337\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.15442758239805698\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.15426031686365604\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.15297502651810646\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.15075298957526684\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.14672558940947056\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.14340142533183098\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.14027996733784676\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.137018334120512\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.13641829416155815\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.13622951321303844\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.14030604250729084\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.145655058324337\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.1549837701022625\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.1635136753320694\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.17054060101509094\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.17225414887070656\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.16755416616797447\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 566476\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 566476\n",
      "ROC-AUC: 0.015869896993270086\n",
      "ROC_PR: 0.0041325509226013395\n",
      "counter für die Anzhal der Files: 9\n",
      "##############Start Training with Dataset 32_shuttle.npz######################\n",
      "Die gesamte Länge der Daten ist 49097\n",
      "Die Länge das Anomalydatensatzen ist 3511 und der normalen daten ist: 45586\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 35 und 455\n",
      "Die ungelabelden parts dazu sind 3476 und 45131\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 224175 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 48607\n",
      "Die länge des ungelabendeten Datenloader ist: 190\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1845.5721719123458\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1100.248772660347\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 691.9813169540336\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 456.21952323391014\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 302.4726563458029\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 212.39690267658668\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 172.91617180985403\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 167.14406631852938\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 174.49819473371113\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 183.9142138076155\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 195.3605152722363\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 203.17216829622174\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 200.27306213117626\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 188.46681791680044\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 169.02675780640345\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 144.45376061739987\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 119.19532219351154\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 98.06079280104267\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 85.54478760723654\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 80.38527594091686\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 79.21763106132751\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 75.57597279657512\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 63.4825881213358\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 55.27304083898187\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 49.62847567693284\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 46.76312737922146\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 43.86615046518578\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 38.671549488420354\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 34.88703987383407\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 34.419913560594324\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 490\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.8189903795719147\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.8195474445819855\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.8180225491523743\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.8181519210338593\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.8171065151691437\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.8166666030883789\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.8160701394081116\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.8159524202346802\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8152114152908325\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.8140004575252533\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8141846060752869\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.8123010993003845\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.8124573826789856\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.8121561408042908\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.8114377856254578\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.8104461133480072\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.8091650903224945\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.8079251348972321\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.8076283037662506\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.8063185513019562\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.8061879873275757\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.8051894307136536\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.8054082095623016\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.8037579357624054\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.8032378554344177\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.8032017052173615\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.8015383780002594\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.8001841306686401\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.7989645302295685\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.7989491820335388\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.7971282601356506\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.7970652282238007\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.7968373894691467\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.7955757677555084\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.7943631410598755\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.7941509783267975\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.7929750978946686\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7927299439907074\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.7910929024219513\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.79018634557724\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 48607\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 48607\n",
      "ROC-AUC: 0.9890695483106983\n",
      "ROC_PR: 0.9161178000303609\n",
      "counter für die Anzhal der Files: 10\n",
      "##############Start Training with Dataset 13_fraud.npz######################\n",
      "Die gesamte Länge der Daten ist 284807\n",
      "Die Länge das Anomalydatensatzen ist 492 und der normalen daten ist: 284315\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 4 und 1000\n",
      "Die ungelabelden parts dazu sind 488 und 283315\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1004016 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 283803\n",
      "Die länge des ungelabendeten Datenloader ist: 1109\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 39.52818719057242\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 38.93356579906164\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 38.15440178357638\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 37.2341463629447\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 36.18239708646395\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 35.02174077143115\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 33.782200240423215\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 32.495042228709366\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 31.19628345037771\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 29.921976246087908\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 28.517899335707284\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 27.161680066634172\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 25.95123688874349\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 24.898280413098508\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 23.910457837587714\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 22.974121557395716\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 22.097024539366842\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 21.383430371474148\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 20.622504905071384\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 19.71860581165306\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 18.852128745371562\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 17.996887548063434\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 17.204531728795814\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 16.496472851589346\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 15.89308947640861\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 15.424328102073398\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 15.10266074518474\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 14.971437040638522\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 15.038725843847802\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 15.26637534311631\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1004\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.027632987931156094\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.02673360330345531\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.026145895828449284\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.02597510887790122\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.02427619979971496\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.023953475858434103\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.02290557834567153\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.02215025068289833\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.022099285572039662\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.02083788220625138\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.01984574810921913\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.019453556858934462\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.01866011376841925\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.018452814081683755\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.01795086797210388\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.01781202736310661\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.017820246750488877\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.0178048288798891\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.01875480846501887\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.018939649453386664\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.020281381672248244\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.02084550412837416\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.02127954736351967\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.022324071964249015\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.02363637532107532\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.02417606208473444\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.024014731869101524\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.024005829822272062\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.023390922462567687\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.021871578646823764\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.021829419070854783\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.02000803896225989\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.01873416919261217\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.01796479261247441\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.018166987225413322\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.017719603143632412\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.017515031329821795\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.018030620296485722\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.01856050523929298\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.019543821588740684\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 283803\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 283803\n",
      "ROC-AUC: 0.9551494629016014\n",
      "ROC_PR: 0.676849447348948\n",
      "counter für die Anzhal der Files: 11\n",
      "##############Start Training with Dataset 9_census.npz######################\n",
      "Die gesamte Länge der Daten ist 299285\n",
      "Die Länge das Anomalydatensatzen ist 18568 und der normalen daten ist: 280717\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 185 und 1000\n",
      "Die ungelabelden parts dazu sind 18383 und 279717\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 1219225 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 298100\n",
      "Die länge des ungelabendeten Datenloader ist: 1165\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1392.3356244305264\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1196.1960901055745\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1073.9252022297323\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1009.3046428288778\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 924.2463171056106\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 881.2976599226172\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 840.5916362973088\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 801.5553351800131\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 768.7192557729544\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 742.7163653488848\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 719.2747448287089\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 691.8164081657582\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 662.4027582521377\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 638.1947958475898\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 612.4618509385907\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 587.928309166504\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 567.5014343197647\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 548.7334198696434\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 530.2697524559891\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 511.1428535008115\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 488.94817149025937\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 466.96111904851483\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 447.90634825468413\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 429.6116548290329\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 412.6330213624841\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 397.33938328568587\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 379.64751699424806\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 360.30726182077854\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 343.48506685777943\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 329.334287160889\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 1185\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 1.0922255277633668\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 1.0746715068817139\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 1.0534250020980835\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 1.023875617980957\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 1.0013466596603393\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.9748435497283936\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.9497997403144837\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.9194898724555969\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.8977415204048157\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.8664625287055969\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.8383975625038147\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.8123290061950683\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.7889218091964721\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.7673578143119812\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.7475319743156433\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.7313287258148193\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.7158338904380799\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.7090880751609803\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.7031089425086975\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.7023261547088623\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.7082073092460632\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.7136680841445923\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.7294907212257385\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.7401237607002258\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.7549468040466308\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.7636976480484009\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.7752528667449952\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.7867741346359253\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.7987058877944946\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.8038780331611634\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.8141584753990173\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.8107539892196656\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.8108273863792419\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.800035047531128\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.7937243819236756\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.7783652424812317\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.7711445689201355\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.7582962274551391\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.7467199444770813\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.731268846988678\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 298100\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 298100\n",
      "ROC-AUC: 0.21520862850802666\n",
      "ROC_PR: 0.04094980715170934\n",
      "counter für die Anzhal der Files: 12\n",
      "##############Start Training with Dataset 1_ALOI.npz######################\n",
      "Die gesamte Länge der Daten ist 49534\n",
      "Die Länge das Anomalydatensatzen ist 1508 und der normalen daten ist: 48026\n",
      "Es werden 1.0% der Daten gelabeld\n",
      "Es wurden zwei Datensätze erstellt, der erste mit der beiden Längen 15 und 480\n",
      "Die ungelabelden parts dazu sind 1493 und 47546\n",
      "Der Siamese Datasatz wurde mit einer gesamtLänge von 237825 erstellt\n",
      "Die länge des ungelabendeten Datensatzen ist: 49039\n",
      "Die länge des ungelabendeten Datenloader ist: 192\n",
      "Das ist die verwendete loss<function binary_cross_entropy at 0x134adc220>\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 302.21948508784385\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 302.122444859609\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 302.0224144773314\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 301.91409067992004\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 301.79631913526646\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 301.6699646042805\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 301.5357478292078\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 301.393593736061\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 301.24416505875547\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 301.083895075715\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 300.9203454699848\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 300.74951496124265\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 300.5729781296775\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 300.3933022804318\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 300.20513889562056\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 300.01723548264033\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 299.8214888002283\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 299.6251934138998\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 299.4277120345382\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 299.22642278088034\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 299.0232729813104\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 298.8206406804663\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 298.62044120318785\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 298.41680378039035\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 298.2156252569209\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 298.02238443987346\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 297.827232217985\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 297.6380938268477\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 297.45245056138725\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 297.275091827797\n",
      "---------Finished Training Siamese Network-------------\n",
      "Die Länge der gelabelten embedded Daten ist 495\n",
      "----------------Start trainign Epoche 0----------------\n",
      "Epoche: 0 Average Loss: 0.9350562393665314\n",
      "----------------Start trainign Epoche 1----------------\n",
      "Epoche: 1 Average Loss: 0.9322852790355682\n",
      "----------------Start trainign Epoche 2----------------\n",
      "Epoche: 2 Average Loss: 0.9301804602146149\n",
      "----------------Start trainign Epoche 3----------------\n",
      "Epoche: 3 Average Loss: 0.9271973371505737\n",
      "----------------Start trainign Epoche 4----------------\n",
      "Epoche: 4 Average Loss: 0.924552321434021\n",
      "----------------Start trainign Epoche 5----------------\n",
      "Epoche: 5 Average Loss: 0.9219529628753662\n",
      "----------------Start trainign Epoche 6----------------\n",
      "Epoche: 6 Average Loss: 0.919206440448761\n",
      "----------------Start trainign Epoche 7----------------\n",
      "Epoche: 7 Average Loss: 0.9162290990352631\n",
      "----------------Start trainign Epoche 8----------------\n",
      "Epoche: 8 Average Loss: 0.9132190942764282\n",
      "----------------Start trainign Epoche 9----------------\n",
      "Epoche: 9 Average Loss: 0.9104879200458527\n",
      "----------------Start trainign Epoche 10----------------\n",
      "Epoche: 10 Average Loss: 0.9073509275913239\n",
      "----------------Start trainign Epoche 11----------------\n",
      "Epoche: 11 Average Loss: 0.9039558172225952\n",
      "----------------Start trainign Epoche 12----------------\n",
      "Epoche: 12 Average Loss: 0.9012207090854645\n",
      "----------------Start trainign Epoche 13----------------\n",
      "Epoche: 13 Average Loss: 0.8979382216930389\n",
      "----------------Start trainign Epoche 14----------------\n",
      "Epoche: 14 Average Loss: 0.894704669713974\n",
      "----------------Start trainign Epoche 15----------------\n",
      "Epoche: 15 Average Loss: 0.8915412724018097\n",
      "----------------Start trainign Epoche 16----------------\n",
      "Epoche: 16 Average Loss: 0.8881179392337799\n",
      "----------------Start trainign Epoche 17----------------\n",
      "Epoche: 17 Average Loss: 0.8850704431533813\n",
      "----------------Start trainign Epoche 18----------------\n",
      "Epoche: 18 Average Loss: 0.8817295730113983\n",
      "----------------Start trainign Epoche 19----------------\n",
      "Epoche: 19 Average Loss: 0.8783476650714874\n",
      "----------------Start trainign Epoche 20----------------\n",
      "Epoche: 20 Average Loss: 0.8750483393669128\n",
      "----------------Start trainign Epoche 21----------------\n",
      "Epoche: 21 Average Loss: 0.8715602457523346\n",
      "----------------Start trainign Epoche 22----------------\n",
      "Epoche: 22 Average Loss: 0.8681082725524902\n",
      "----------------Start trainign Epoche 23----------------\n",
      "Epoche: 23 Average Loss: 0.8647139966487885\n",
      "----------------Start trainign Epoche 24----------------\n",
      "Epoche: 24 Average Loss: 0.8615539371967316\n",
      "----------------Start trainign Epoche 25----------------\n",
      "Epoche: 25 Average Loss: 0.8579914569854736\n",
      "----------------Start trainign Epoche 26----------------\n",
      "Epoche: 26 Average Loss: 0.8546091318130493\n",
      "----------------Start trainign Epoche 27----------------\n",
      "Epoche: 27 Average Loss: 0.8512529134750366\n",
      "----------------Start trainign Epoche 28----------------\n",
      "Epoche: 28 Average Loss: 0.8478985130786896\n",
      "----------------Start trainign Epoche 29----------------\n",
      "Epoche: 29 Average Loss: 0.8443475961685181\n",
      "----------------Start trainign Epoche 30----------------\n",
      "Epoche: 30 Average Loss: 0.8410374820232391\n",
      "----------------Start trainign Epoche 31----------------\n",
      "Epoche: 31 Average Loss: 0.8376717269420624\n",
      "----------------Start trainign Epoche 32----------------\n",
      "Epoche: 32 Average Loss: 0.834267258644104\n",
      "----------------Start trainign Epoche 33----------------\n",
      "Epoche: 33 Average Loss: 0.8308943808078766\n",
      "----------------Start trainign Epoche 34----------------\n",
      "Epoche: 34 Average Loss: 0.8274085521697998\n",
      "----------------Start trainign Epoche 35----------------\n",
      "Epoche: 35 Average Loss: 0.8242509365081787\n",
      "----------------Start trainign Epoche 36----------------\n",
      "Epoche: 36 Average Loss: 0.820784717798233\n",
      "----------------Start trainign Epoche 37----------------\n",
      "Epoche: 37 Average Loss: 0.8173937201499939\n",
      "----------------Start trainign Epoche 38----------------\n",
      "Epoche: 38 Average Loss: 0.8140161633491516\n",
      "----------------Start trainign Epoche 39----------------\n",
      "Epoche: 39 Average Loss: 0.810654878616333\n",
      "------------------Finished Training Classifier----------------------\n",
      "Das ist die länge der ungelabelten Daten nach dem Siamese 49039\n",
      "Das ist die länge der ungelabelten Labels nach dem Siamese 49039\n",
      "ROC-AUC: 0.4769933944041894\n",
      "ROC_PR: 0.02873836736834581\n"
     ]
    }
   ],
   "source": [
    "roc_all_1_percent = []\n",
    "pr_all_1_percent = []\n",
    "\n",
    "counter = 0\n",
    "for file in medium_files:\n",
    "    print(f'counter für die Anzhal der Files: {counter}')\n",
    "    roc, pr = train_dataset(file, \n",
    "                            random_seed=random_seed,\n",
    "                            percentage_labeld=0.01,\n",
    "                            contrastiv_margin=10.0,\n",
    "                            lr_siamese=0.00001,\n",
    "                            lr_classifier=0.0001,\n",
    "                            epochs_siamese=30,\n",
    "                            epochs_classifier=40,\n",
    "                            print_embeddeds=False,\n",
    "                            print_learning=False,\n",
    "                            )\n",
    "    \n",
    "    roc_all_1_percent.append(roc)\n",
    "    pr_all_1_percent.append(pr)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(roc_all_1_percent)), roc_all_1_percent, marker='o', color='b')\n",
    "plt.plot(range(len(pr_all_1_percent)), pr_all_1_percent, marker='x', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_all_ens = []\n",
    "pr_all_ens = []\n",
    "\n",
    "counter = 0\n",
    "for file in medium_files:\n",
    "    print(f'counter für die Anzhal der Files: {counter}')\n",
    "    roc, pr = bagging_ensamble_training(file, \n",
    "                            random_seed=random_seed,\n",
    "                            percentage_labeld=0.05,\n",
    "                            contrastiv_margin=10.0,\n",
    "                            lr_siamese=0.00001,\n",
    "                            lr_classifier=0.0001,\n",
    "                            epochs_siamese=20,\n",
    "                            epochs_classifier=40,\n",
    "                            print_embeddeds=False,\n",
    "                            print_learning=False,\n",
    "                            len_dataset=100000,\n",
    "                            )\n",
    "    \n",
    "    roc_all_ens.append(roc)\n",
    "    pr_all_ens.append(pr)\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
